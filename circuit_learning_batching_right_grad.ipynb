{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "qnn",
   "display_name": "qnn",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pennylane import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.linalg import expm\n",
    "from copy import deepcopy\n",
    "import pennylane as qml\n",
    "import pandas as pd\n",
    "from math import pi\n",
    "import numpy as np\n",
    "import random\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "devSet = pd.read_csv(\"./us_migration.csv\")\n",
    "devSet = devSet.loc[:, ~devSet.columns.str.contains('^Unnamed')]\n",
    "devSet = devSet.apply(lambda x: pd.to_numeric(x, errors='coerce'))\n",
    "devSet = devSet.dropna(axis=1)\n",
    "\n",
    "y = torch.Tensor(devSet['US_MIG_05_10'].values)\n",
    "X = devSet.loc[:, devSet.columns != \"US_MIG_05_10\"].values\n",
    "\n",
    "mMScale = preprocessing.MinMaxScaler()\n",
    "X = mMScale.fit_transform(X)\n",
    "\n",
    "indices = random.sample(range(0, 10), 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 0, 1, 2]"
      ]
     },
     "metadata": {},
     "execution_count": 38
    }
   ],
   "source": [
    "[i for i in range(5)]\n",
    "[i % 5 for i in range(8)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[0, 1, 2, 3]"
      ]
     },
     "metadata": {},
     "execution_count": 39
    }
   ],
   "source": [
    "[i % 5 for i in range(8)][0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[4, 0, 1, 2]"
      ]
     },
     "metadata": {},
     "execution_count": 40
    }
   ],
   "source": [
    "[i % 5 for i in range(8)][4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "devX = qml.device('default.qubit', wires = 5)\n",
    "devY = qml.device('default.qubit', wires = 5)\n",
    "devZ = qml.device('default.qubit', wires = 5)\n",
    "\n",
    "@qml.qnode(devX)\n",
    "def rotation_circuitX(vals, thetas):\n",
    "\n",
    "    # Apply Hadamards\n",
    "    for hadamard_wire in range(len(vals)):\n",
    "        qml.Hadamard(wires = hadamard_wire)\n",
    "\n",
    "    # Apply value dependent Z-axis rotations\n",
    "    for rotation_val in range(len(vals)):\n",
    "        qml.RZ(vals[rotation_val], wires = rotation_val)\n",
    "\n",
    "\n",
    "\n",
    "    # Parametized rotation <- this is what is being trained\n",
    "    # ws = [i for i in range(len(vals))]\n",
    "\n",
    "    theta_indices = [i % len(vals) for i in range(len(thetas))]\n",
    "    curIn = [0,1,2,3]\n",
    "    for theta in range(len(curIn)):\n",
    "        qml.RX(thetas[theta], wires=curIn[theta])\n",
    "\n",
    "    # CNOT's\n",
    "    qml.CNOT(wires = [0,1])\n",
    "    qml.CNOT(wires = [1,2])\n",
    "    qml.CNOT(wires = [2,3])\n",
    "    qml.CNOT(wires = [3,4])\n",
    "\n",
    "    theta_indices = [i % len(vals) for i in range(len(thetas))]\n",
    "    curIn = [4,5,6,7]\n",
    "    for theta in range(len(curIn)):\n",
    "        qml.RX(thetas[curIn[theta]], wires=theta)\n",
    "\n",
    "    # CNOT's\n",
    "    qml.CNOT(wires = [1,0])\n",
    "    qml.CNOT(wires = [2,1])\n",
    "    qml.CNOT(wires = [3,2])\n",
    "    qml.CNOT(wires = [4,3])\n",
    "\n",
    "\n",
    "    # Get expected values & return them\n",
    "    expected_values = [qml.expval(qml.PauliX(wire)) for wire in range(len(vals))]\n",
    "    return expected_values\n",
    "\n",
    "\n",
    "@qml.qnode(devY)\n",
    "def rotation_circuitY(vals, thetas):\n",
    "\n",
    "    # Apply Hadamards\n",
    "    for hadamard_wire in range(len(vals)):\n",
    "        qml.Hadamard(wires = hadamard_wire)\n",
    "\n",
    "    # Apply value dependent Z-axis rotations\n",
    "    for rotation_val in range(len(vals)):\n",
    "        qml.RZ(vals[rotation_val], wires = rotation_val)\n",
    "\n",
    "\n",
    "\n",
    "    # Parametized rotation <- this is what is being trained\n",
    "    theta_indices = [i % len(vals) for i in range(len(thetas))]\n",
    "    curIn = [0,1,2,3]\n",
    "    for theta in range(len(curIn)):\n",
    "        qml.RX(thetas[theta], wires=curIn[theta])\n",
    "\n",
    "    # CNOT's\n",
    "    qml.CNOT(wires = [0,1])\n",
    "    qml.CNOT(wires = [1,2])\n",
    "    qml.CNOT(wires = [2,3])\n",
    "    qml.CNOT(wires = [3,4])\n",
    "\n",
    "    theta_indices = [i % len(vals) for i in range(len(thetas))]\n",
    "    curIn = [4,5,6,7]\n",
    "    for theta in range(len(curIn)):\n",
    "        qml.RX(thetas[curIn[theta]], wires=theta)\n",
    "\n",
    "    # CNOT's\n",
    "    qml.CNOT(wires = [1,0])\n",
    "    qml.CNOT(wires = [2,1])\n",
    "    qml.CNOT(wires = [3,2])\n",
    "    qml.CNOT(wires = [4,3])\n",
    "\n",
    "    # Get expected values & return them\n",
    "    expected_values = [qml.expval(qml.PauliY(wire)) for wire in range(len(vals))]\n",
    "    return expected_values\n",
    "\n",
    "\n",
    "@qml.qnode(devZ)\n",
    "def rotation_circuitZ(vals, thetas):\n",
    "\n",
    "    # Apply Hadamards\n",
    "    for hadamard_wire in range(len(vals)):\n",
    "        qml.Hadamard(wires = hadamard_wire)\n",
    "\n",
    "    # Apply value dependent Z-axis rotations\n",
    "    for rotation_val in range(len(vals)):\n",
    "        qml.RZ(vals[rotation_val], wires = rotation_val)\n",
    "\n",
    "\n",
    "\n",
    "    # Parametized rotation <- this is what is being trained\n",
    "    theta_indices = [i % len(vals) for i in range(len(thetas))]\n",
    "    curIn = [0,1,2,3]\n",
    "    for theta in range(len(curIn)):\n",
    "        qml.RX(thetas[theta], wires=curIn[theta])\n",
    "\n",
    "    # CNOT's\n",
    "    qml.CNOT(wires = [0,1])\n",
    "    qml.CNOT(wires = [1,2])\n",
    "    qml.CNOT(wires = [2,3])\n",
    "    qml.CNOT(wires = [3,4])\n",
    "\n",
    "    # Parametized rotation <- this is what is being trained\n",
    "    theta_indices = [i % len(vals) for i in range(len(thetas))]\n",
    "    curIn = [4,5,6,7]\n",
    "    for theta in range(len(curIn)):\n",
    "        qml.RX(thetas[curIn[theta]], wires=theta)\n",
    "\n",
    "    # CNOT's\n",
    "    qml.CNOT(wires = [1,0])\n",
    "    qml.CNOT(wires = [2,1])\n",
    "    qml.CNOT(wires = [3,2])\n",
    "    qml.CNOT(wires = [4,3])\n",
    "\n",
    "    # Get expected values & return them\n",
    "    expected_values = [qml.expval(qml.PauliZ(wire)) for wire in range(len(vals))]\n",
    "    return expected_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Define our model\n",
    "class QuantumCicuitNet(torch.nn.Module):\n",
    "    def __init__(self, n_vals, n_dim, batch_size):\n",
    "        super().__init__()\n",
    "        self.relu = torch.nn.ReLU(inplace=True)\n",
    "        self.conv2d = torch.nn.Conv2d(3, 1, kernel_size=(3,3), stride=(2,2), padding=(2,2), bias=False)\n",
    "        self.linear = torch.nn.Linear(batch_size*1*4*2, n_dim)  \n",
    "\n",
    "\n",
    "    def param_shift(self, vals, thetas):\n",
    "\n",
    "        mean_grads = []\n",
    "\n",
    "        for batch in range(len(vals)):\n",
    "\n",
    "            cur_vals = vals[batch]\n",
    "            gradXs, gradYs, gradZs = [], [], []\n",
    "\n",
    "            for i in range(len(thetas)):\n",
    "\n",
    "                cur_rs, cur_ls = deepcopy(thetas), deepcopy(thetas)\n",
    "                cur_rs[i], cur_ls[i] = cur_rs[i] + (np.pi / 2), cur_ls[i] - (np.pi / 2)\n",
    "\n",
    "                # print(\"RS: \", cur_rs)\n",
    "            \n",
    "\n",
    "                # Get the ouput of a shift right and left for each of the X, Y and Z circuits (output shape is 5 for each of the variables/qubits)\n",
    "                r_plusX  = rotation_circuitX(cur_vals, np.array(cur_rs))\n",
    "                r_minusX = rotation_circuitX(cur_vals, np.array(cur_ls))\n",
    "                r_plusY  = rotation_circuitY(cur_vals, np.array(cur_rs))\n",
    "                r_minusY = rotation_circuitY(cur_vals, np.array(cur_ls))\n",
    "                r_plusZ  = rotation_circuitZ(cur_vals, np.array(cur_rs))\n",
    "                r_minusZ = rotation_circuitZ(cur_vals, np.array(cur_ls))\n",
    "\n",
    "                # print(\"R MINUS: \", r_minusX, \"  R Plus: \", r_plusX)\n",
    "\n",
    "                # using the convention u=1/2\n",
    "                # Caculate the gradient (shape here is 5 again)\n",
    "                gradX = torch.tensor(.5 * (r_plusX - r_minusX))\n",
    "                gradY = torch.tensor(.5 * (r_plusY - r_minusY))\n",
    "                gradZ = torch.tensor(.5 * (r_plusZ - r_minusZ))  \n",
    "\n",
    "                # Append the maximum gradient to the list of overall gradients\n",
    "                gradXs.append(torch.max(gradX).detach().numpy())\n",
    "                gradYs.append(torch.max(gradY).detach().numpy())\n",
    "                gradZs.append(torch.max(gradZ).detach().numpy())\n",
    "            \n",
    "            cur_grads = torch.tensor(np.reshape(np.concatenate([gradXs, gradYs, gradZs]), (3, 8)))\n",
    "            cur_means = torch.mean(input = cur_grads, dim = 0)\n",
    "            mean_grads.append(cur_means)\n",
    "\n",
    "            # print(\"MEAN GRADS\")\n",
    "            # print(mean_grads)\n",
    "\n",
    "        mean_grads = torch.tensor([i.detach().numpy() for i in mean_grads])\n",
    "        mean_grads = torch.reshape(torch.tensor(mean_grads), (len(vals), len(thetas)))\n",
    "        mean_grads = torch.mean(input = mean_grads, dim = 0)\n",
    "\n",
    "        return mean_grads\n",
    "\n",
    "\n",
    "    def run_circs(self, x, thetas):\n",
    "        outs = []\n",
    "        for i in range(0, x.shape[0]):\n",
    "            outX = torch.tensor(rotation_circuitX(x[i], thetas), dtype = torch.float32) * 100# OUT:  torch.Size([100, 1, 10, 10])\n",
    "            outY = torch.tensor(rotation_circuitY(x[i], thetas), dtype = torch.float32) * 100# OUT:  torch.Size([100, 1, 10, 10])\n",
    "            outZ = torch.tensor(rotation_circuitZ(x[i], thetas), dtype = torch.float32) * 100# OUT:  torch.Size([100, 1, 10, 10])\n",
    "            outs.append(torch.reshape(torch.cat((outX, outY,outZ), 0), (3, 5)))\n",
    "        return torch.reshape(torch.cat(outs), (x.shape[0], 3, x.shape[1], 1))\n",
    "\n",
    "        \n",
    "    def forward(self, x, thetas):\n",
    "        out = self.run_circs(x, thetas)\n",
    "        grads = self.param_shift(x, thetas)\n",
    "        out = self.conv2d(out)\n",
    "        out = self.relu(out)\n",
    "        out = out.flatten()\n",
    "        out = self.linear(out)\n",
    "        return out, grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mae(real, pred):\n",
    "    '''\n",
    "    Calculates MAE of an epoch\n",
    "    '''\n",
    "    return torch.abs(real - pred).mean()"
   ]
  },
  {
   "source": [
    "## Training without the theta updates"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "rd0>)\n",
      "    Thetas:  tensor([0.5000, 0.5307, 0.5073, 0.5053, 0.5016, 0.5289, 0.5064, 0.6931],\n",
      "       dtype=torch.float64)\n",
      "\n",
      "\n",
      "EPOCH:  49\n",
      "    Loss:  tensor(260561.2500, grad_fn=<MseLossBackward>)\n",
      "    MAE:   tensor(173.0223, grad_fn=<MeanBackward0>)\n",
      "    Y T:   tensor([ 51., 574.,  12., 201., 109.])\n",
      "    Y P:   tensor([140.7966, 103.9146, 129.9733, 101.5675, 196.8239],\n",
      "       grad_fn=<AddBackward0>)\n",
      "    Thetas:  tensor([0.5000, 0.5314, 0.5073, 0.5053, 0.5016, 0.5296, 0.5065, 0.6991],\n",
      "       dtype=torch.float64)\n",
      "\n",
      "\n",
      "EPOCH:  50\n",
      "    Loss:  tensor(73703.1328, grad_fn=<MseLossBackward>)\n",
      "    MAE:   tensor(101.3876, grad_fn=<MeanBackward0>)\n",
      "    Y T:   tensor([273., 170., 271., 105.,  26.])\n",
      "    Y P:   tensor([149.0271, 190.6124, 115.8593, 129.9549, 208.2569],\n",
      "       grad_fn=<AddBackward0>)\n",
      "    Thetas:  tensor([0.5000, 0.5312, 0.5073, 0.5053, 0.5016, 0.5294, 0.5065, 0.6990],\n",
      "       dtype=torch.float64)\n",
      "\n",
      "\n",
      "EPOCH:  51\n",
      "    Loss:  tensor(961485.9375, grad_fn=<MseLossBackward>)\n",
      "    MAE:   tensor(297.0391, grad_fn=<MeanBackward0>)\n",
      "    Y T:   tensor([  66., 1119.,  242.,  335.,  313.])\n",
      "    Y P:   tensor([163.2466, 182.3257, 144.0765, 121.9047, 172.7443],\n",
      "       grad_fn=<AddBackward0>)\n",
      "    Thetas:  tensor([0.5000, 0.5313, 0.5074, 0.5053, 0.5016, 0.5295, 0.5065, 0.7017],\n",
      "       dtype=torch.float64)\n",
      "\n",
      "\n",
      "EPOCH:  52\n",
      "    Loss:  tensor(268251.9062, grad_fn=<MseLossBackward>)\n",
      "    MAE:   tensor(196.7433, grad_fn=<MeanBackward0>)\n",
      "    Y T:   tensor([565., 260., 154., 107., 355.])\n",
      "    Y P:   tensor([239.3429, 600.8459, 300.1280, 263.3769, 340.2914],\n",
      "       grad_fn=<AddBackward0>)\n",
      "    Thetas:  tensor([0.5000, 0.5319, 0.5078, 0.5053, 0.5019, 0.5300, 0.5066, 0.7059],\n",
      "       dtype=torch.float64)\n",
      "\n",
      "\n",
      "EPOCH:  53\n",
      "    Loss:  tensor(193234.8281, grad_fn=<MseLossBackward>)\n",
      "    MAE:   tensor(162.1353, grad_fn=<MeanBackward0>)\n",
      "    Y T:   tensor([350.,  10.,  32.,  49., 545.])\n",
      "    Y P:   tensor([323.1107, 312.6732, 141.8339, 134.8582, 259.5782],\n",
      "       grad_fn=<AddBackward0>)\n",
      "    Thetas:  tensor([0.5000, 0.5325, 0.5078, 0.5053, 0.5017, 0.5306, 0.5066, 0.7085],\n",
      "       dtype=torch.float64)\n",
      "\n",
      "\n",
      "EPOCH:  54\n",
      "    Loss:  tensor(194050.7812, grad_fn=<MseLossBackward>)\n",
      "    MAE:   tensor(173.5954, grad_fn=<MeanBackward0>)\n",
      "    Y T:   tensor([ 47., 109., 176., 268., 614.])\n",
      "    Y P:   tensor([339.6944, 203.9847, 111.6959, 125.9514, 340.0550],\n",
      "       grad_fn=<AddBackward0>)\n",
      "    Thetas:  tensor([0.5000, 0.5326, 0.5078, 0.5053, 0.5018, 0.5308, 0.5066, 0.7116],\n",
      "       dtype=torch.float64)\n",
      "\n",
      "\n",
      "EPOCH:  55\n",
      "    Loss:  tensor(1320340.6250, grad_fn=<MseLossBackward>)\n",
      "    MAE:   tensor(347.7339, grad_fn=<MeanBackward0>)\n",
      "    Y T:   tensor([ 377.,  279., 1193.,  100.,   27.])\n",
      "    Y P:   tensor([231.6373, 165.6403, 122.2265, 137.1168, 399.0568],\n",
      "       grad_fn=<AddBackward0>)\n",
      "    Thetas:  tensor([0.5000, 0.5330, 0.5078, 0.5053, 0.5018, 0.5311, 0.5067, 0.7130],\n",
      "       dtype=torch.float64)\n",
      "\n",
      "\n",
      "EPOCH:  56\n",
      "    Loss:  tensor(200640.3438, grad_fn=<MseLossBackward>)\n",
      "    MAE:   tensor(182.2433, grad_fn=<MeanBackward0>)\n",
      "    Y T:   tensor([ 24.,   7., 122., 109.,  82.])\n",
      "    Y P:   tensor([257.7940, 186.9968, 386.1199, 134.5303, 289.7757],\n",
      "       grad_fn=<AddBackward0>)\n",
      "    Thetas:  tensor([0.5000, 0.5337, 0.5078, 0.5053, 0.5018, 0.5318, 0.5067, 0.7166],\n",
      "       dtype=torch.float64)\n",
      "\n",
      "\n",
      "EPOCH:  57\n",
      "    Loss:  tensor(387114.8125, grad_fn=<MseLossBackward>)\n",
      "    MAE:   tensor(183.7294, grad_fn=<MeanBackward0>)\n",
      "    Y T:   tensor([708., 207.,  50., 154., 122.])\n",
      "    Y P:   tensor([112.3192,  89.0879, 154.1592,  68.6457, 137.5407],\n",
      "       grad_fn=<AddBackward0>)\n",
      "    Thetas:  tensor([0.5000, 0.5343, 0.5080, 0.5053, 0.5018, 0.5324, 0.5068, 0.7231],\n",
      "       dtype=torch.float64)\n",
      "\n",
      "\n",
      "EPOCH:  58\n",
      "    Loss:  tensor(83353.1797, grad_fn=<MseLossBackward>)\n",
      "    MAE:   tensor(110.5888, grad_fn=<MeanBackward0>)\n",
      "    Y T:   tensor([142., 161.,  87.,  30.,   0.])\n",
      "    Y P:   tensor([228.9636, 142.8569, 247.0646, 108.9477, 208.8251],\n",
      "       grad_fn=<AddBackward0>)\n",
      "    Thetas:  tensor([0.5000, 0.5342, 0.5079, 0.5053, 0.5018, 0.5323, 0.5067, 0.7224],\n",
      "       dtype=torch.float64)\n",
      "\n",
      "\n",
      "EPOCH:  59\n",
      "    Loss:  tensor(564859.3125, grad_fn=<MseLossBackward>)\n",
      "    MAE:   tensor(289.2547, grad_fn=<MeanBackward0>)\n",
      "    Y T:   tensor([  0., 438.,   2., 614., 411.])\n",
      "    Y P:   tensor([108.0514,  83.2736, 104.1122,  53.9177,  89.6991],\n",
      "       grad_fn=<AddBackward0>)\n",
      "    Thetas:  tensor([0.5000, 0.5344, 0.5080, 0.5053, 0.5018, 0.5325, 0.5068, 0.7243],\n",
      "       dtype=torch.float64)\n",
      "\n",
      "\n",
      "EPOCH:  60\n",
      "    Loss:  tensor(247334.7656, grad_fn=<MseLossBackward>)\n",
      "    MAE:   tensor(175.1104, grad_fn=<MeanBackward0>)\n",
      "    Y T:   tensor([216.,  87., 576., 439.,  84.])\n",
      "    Y P:   tensor([198.4629, 169.9952, 197.7177, 144.8680, 186.6056],\n",
      "       grad_fn=<AddBackward0>)\n",
      "    Thetas:  tensor([0.5000, 0.5346, 0.5081, 0.5053, 0.5018, 0.5327, 0.5068, 0.7279],\n",
      "       dtype=torch.float64)\n",
      "\n",
      "\n",
      "EPOCH:  61\n",
      "    Loss:  tensor(140354.9844, grad_fn=<MseLossBackward>)\n",
      "    MAE:   tensor(119.8238, grad_fn=<MeanBackward0>)\n",
      "    Y T:   tensor([182., 194.,  43., 392., 269.])\n",
      "    Y P:   tensor([283.7544, 197.1617, 369.5126, 239.8887, 253.4209],\n",
      "       grad_fn=<AddBackward0>)\n",
      "    Thetas:  tensor([0.5000, 0.5351, 0.5081, 0.5053, 0.5018, 0.5332, 0.5068, 0.7311],\n",
      "       dtype=torch.float64)\n",
      "\n",
      "\n",
      "EPOCH:  62\n",
      "    Loss:  tensor(120030.3047, grad_fn=<MseLossBackward>)\n",
      "    MAE:   tensor(153.2816, grad_fn=<MeanBackward0>)\n",
      "    Y T:   tensor([289., 309.,   0.,  35., 300.])\n",
      "    Y P:   tensor([172.4902, 149.6525, 172.7329, 212.9277, 160.1098],\n",
      "       grad_fn=<AddBackward0>)\n",
      "    Thetas:  tensor([0.5000, 0.5367, 0.5089, 0.5053, 0.5018, 0.5343, 0.5069, 0.7395],\n",
      "       dtype=torch.float64)\n",
      "\n",
      "\n",
      "EPOCH:  63\n",
      "    Loss:  tensor(228213.0156, grad_fn=<MseLossBackward>)\n",
      "    MAE:   tensor(188.2209, grad_fn=<MeanBackward0>)\n",
      "    Y T:   tensor([570., 309., 326., 108.,   3.])\n",
      "    Y P:   tensor([193.3497, 178.0422, 164.8610, 188.7592, 194.5980],\n",
      "       grad_fn=<AddBackward0>)\n",
      "    Thetas:  tensor([0.5000, 0.5362, 0.5085, 0.5053, 0.5018, 0.5340, 0.5069, 0.7393],\n",
      "       dtype=torch.float64)\n",
      "\n",
      "\n",
      "EPOCH:  64\n",
      "    Loss:  tensor(109999., grad_fn=<MseLossBackward>)\n",
      "    MAE:   tensor(126.6872, grad_fn=<MeanBackward0>)\n",
      "    Y T:   tensor([345., 320., 446., 443., 357.])\n",
      "    Y P:   tensor([330.8690, 251.8265, 244.9987, 226.3745, 223.4951],\n",
      "       grad_fn=<AddBackward0>)\n",
      "    Thetas:  tensor([0.5000, 0.5365, 0.5087, 0.5053, 0.5018, 0.5344, 0.5070, 0.7446],\n",
      "       dtype=torch.float64)\n",
      "\n",
      "\n",
      "EPOCH:  65\n",
      "    Loss:  tensor(441936.2500, grad_fn=<MseLossBackward>)\n",
      "    MAE:   tensor(267.0487, grad_fn=<MeanBackward0>)\n",
      "    Y T:   tensor([  8., 706., 168., 178., 419.])\n",
      "    Y P:   tensor([460.9295, 366.7609, 438.0943, 390.3118, 358.3313],\n",
      "       grad_fn=<AddBackward0>)\n",
      "    Thetas:  tensor([0.5000, 0.5369, 0.5089, 0.5053, 0.5018, 0.5347, 0.5070, 0.7500],\n",
      "       dtype=torch.float64)\n",
      "\n",
      "\n",
      "EPOCH:  66\n",
      "    Loss:  tensor(441303.5312, grad_fn=<MseLossBackward>)\n",
      "    MAE:   tensor(226.6853, grad_fn=<MeanBackward0>)\n",
      "    Y T:   tensor([686.,   0.,  38., 102., 269.])\n",
      "    Y P:   tensor([125.8106, 320.7626, 168.9473, 168.7251, 214.1978],\n",
      "       grad_fn=<AddBackward0>)\n",
      "    Thetas:  tensor([0.5000, 0.5374, 0.5090, 0.5053, 0.5018, 0.5352, 0.5070, 0.7511],\n",
      "       dtype=torch.float64)\n",
      "\n",
      "\n",
      "EPOCH:  67\n",
      "    Loss:  tensor(316537.6875, grad_fn=<MseLossBackward>)\n",
      "    MAE:   tensor(214.0897, grad_fn=<MeanBackward0>)\n",
      "    Y T:   tensor([ 32., 652., 352., 274.,  98.])\n",
      "    Y P:   tensor([168.6759, 196.9660, 106.1209, 117.3638, 174.2234],\n",
      "       grad_fn=<AddBackward0>)\n",
      "    Thetas:  tensor([0.5000, 0.5378, 0.5090, 0.5053, 0.5018, 0.5356, 0.5071, 0.7530],\n",
      "       dtype=torch.float64)\n",
      "\n",
      "\n",
      "EPOCH:  68\n",
      "    Loss:  tensor(145774.6719, grad_fn=<MseLossBackward>)\n",
      "    MAE:   tensor(153.1254, grad_fn=<MeanBackward0>)\n",
      "    Y T:   tensor([108., 205., 434., 236.,  44.])\n",
      "    Y P:   tensor([246.7409, 355.7760, 185.8298, 212.1011, 248.0408],\n",
      "       grad_fn=<AddBackward0>)\n",
      "    Thetas:  tensor([0.5000, 0.5388, 0.5091, 0.5053, 0.5018, 0.5365, 0.5071, 0.7581],\n",
      "       dtype=torch.float64)\n",
      "\n",
      "\n",
      "EPOCH:  69\n",
      "    Loss:  tensor(64907.7500, grad_fn=<MseLossBackward>)\n",
      "    MAE:   tensor(87.3465, grad_fn=<MeanBackward0>)\n",
      "    Y T:   tensor([  6., 385., 225.,  32., 200.])\n",
      "    Y P:   tensor([189.1246, 295.5417, 220.2776, 184.6503, 193.2231],\n",
      "       grad_fn=<AddBackward0>)\n",
      "    Thetas:  tensor([0.5000, 0.5388, 0.5090, 0.5053, 0.5018, 0.5366, 0.5071, 0.7609],\n",
      "       dtype=torch.float64)\n",
      "\n",
      "\n",
      "EPOCH:  70\n",
      "    Loss:  tensor(333300.7188, grad_fn=<MseLossBackward>)\n",
      "    MAE:   tensor(223.1581, grad_fn=<MeanBackward0>)\n",
      "    Y T:   tensor([189., 151., 544., 354., 568.])\n",
      "    Y P:   tensor([149.3686, 284.2168, 198.2933, 145.1740, 179.5905],\n",
      "       grad_fn=<AddBackward0>)\n",
      "    Thetas:  tensor([0.5000, 0.5389, 0.5092, 0.5053, 0.5018, 0.5367, 0.5071, 0.7655],\n",
      "       dtype=torch.float64)\n",
      "\n",
      "\n",
      "EPOCH:  71\n",
      "    Loss:  tensor(385422.0625, grad_fn=<MseLossBackward>)\n",
      "    MAE:   tensor(207.9824, grad_fn=<MeanBackward0>)\n",
      "    Y T:   tensor([322., 900.,   9., 203., 400.])\n",
      "    Y P:   tensor([247.0433, 428.6588, 397.5875, 279.2354, 371.2090],\n",
      "       grad_fn=<AddBackward0>)\n",
      "    Thetas:  tensor([0.5000, 0.5393, 0.5092, 0.5053, 0.5018, 0.5370, 0.5071, 0.7689],\n",
      "       dtype=torch.float64)\n",
      "\n",
      "\n",
      "EPOCH:  72\n",
      "    Loss:  tensor(262205.2188, grad_fn=<MseLossBackward>)\n",
      "    MAE:   tensor(185.0124, grad_fn=<MeanBackward0>)\n",
      "    Y T:   tensor([387., 462.,  89., 282.,  28.])\n",
      "    Y P:   tensor([304.9853, 684.6165, 290.2309, 269.3296, 434.5295],\n",
      "       grad_fn=<AddBackward0>)\n",
      "    Thetas:  tensor([0.5000, 0.5394, 0.5093, 0.5053, 0.5018, 0.5371, 0.5072, 0.7711],\n",
      "       dtype=torch.float64)\n",
      "\n",
      "\n",
      "EPOCH:  73\n",
      "    Loss:  tensor(337004.5312, grad_fn=<MseLossBackward>)\n",
      "    MAE:   tensor(232.1236, grad_fn=<MeanBackward0>)\n",
      "    Y T:   tensor([440.,   6.,  12., 536., 270.])\n",
      "    Y P:   tensor([153.2801, 243.6057,  73.2171, 127.5565, 103.3682],\n",
      "       grad_fn=<AddBackward0>)\n",
      "    Thetas:  tensor([0.5000, 0.5399, 0.5093, 0.5053, 0.5018, 0.5376, 0.5072, 0.7752],\n",
      "       dtype=torch.float64)\n",
      "\n",
      "\n",
      "EPOCH:  74\n",
      "    Loss:  tensor(2460398.5000, grad_fn=<MseLossBackward>)\n",
      "    MAE:   tensor(433.2844, grad_fn=<MeanBackward0>)\n",
      "    Y T:   tensor([ 438.,  553.,   92., 1698.,   20.])\n",
      "    Y P:   tensor([199.9823, 266.8839,  88.7956, 178.9671, 140.0508],\n",
      "       grad_fn=<AddBackward0>)\n",
      "    Thetas:  tensor([0.5000, 0.5403, 0.5095, 0.5053, 0.5018, 0.5379, 0.5073, 0.7758],\n",
      "       dtype=torch.float64)\n",
      "\n",
      "\n",
      "EPOCH:  75\n",
      "    Loss:  tensor(876609.6875, grad_fn=<MseLossBackward>)\n",
      "    MAE:   tensor(355.8714, grad_fn=<MeanBackward0>)\n",
      "    Y T:   tensor([ 97., 130.,  22., 500., 306.])\n",
      "    Y P:   tensor([590.6783, 777.4005, 238.1874, 908.4622, 319.6287],\n",
      "       grad_fn=<AddBackward0>)\n",
      "    Thetas:  tensor([0.5000, 0.5406, 0.5095, 0.5053, 0.5018, 0.5383, 0.5072, 0.7819],\n",
      "       dtype=torch.float64)\n",
      "\n",
      "\n",
      "EPOCH:  76\n",
      "    Loss:  tensor(259006.9062, grad_fn=<MseLossBackward>)\n",
      "    MAE:   tensor(129.8638, grad_fn=<MeanBackward0>)\n",
      "    Y T:   tensor([ 66., 144.,   0., 647., 133.])\n",
      "    Y P:   tensor([ 69.8224,  83.0810,  26.0507, 145.6708,  75.8022],\n",
      "       grad_fn=<AddBackward0>)\n",
      "    Thetas:  tensor([0.5000, 0.5408, 0.5096, 0.5053, 0.5018, 0.5384, 0.5073, 0.7871],\n",
      "       dtype=torch.float64)\n",
      "\n",
      "\n",
      "EPOCH:  77\n",
      "    Loss:  tensor(2321558.5000, grad_fn=<MseLossBackward>)\n",
      "    MAE:   tensor(416.0427, grad_fn=<MeanBackward0>)\n",
      "    Y T:   tensor([ 397.,  259.,    0., 1774.,  258.])\n",
      "    Y P:   tensor([ 92.2205, 120.6905,  35.2845, 292.8786, 137.2812],\n",
      "       grad_fn=<AddBackward0>)\n",
      "    Thetas:  tensor([0.5000, 0.5409, 0.5095, 0.5053, 0.5018, 0.5386, 0.5073, 0.7879],\n",
      "       dtype=torch.float64)\n",
      "\n",
      "\n",
      "EPOCH:  78\n",
      "    Loss:  tensor(1771387.2500, grad_fn=<MseLossBackward>)\n",
      "    MAE:   tensor(471.1195, grad_fn=<MeanBackward0>)\n",
      "    Y T:   tensor([1066.,   22.,   85.,   98.,   50.])\n",
      "    Y P:   tensor([ 253.2051,  234.5785,   38.4140, 1085.8887,  345.7498],\n",
      "       grad_fn=<AddBackward0>)\n",
      "    Thetas:  tensor([0.5000, 0.5418, 0.5096, 0.5053, 0.5018, 0.5394, 0.5073, 0.7912],\n",
      "       dtype=torch.float64)\n",
      "\n",
      "\n",
      "EPOCH:  79\n",
      "    Loss:  tensor(144236.3281, grad_fn=<MseLossBackward>)\n",
      "    MAE:   tensor(144.4867, grad_fn=<MeanBackward0>)\n",
      "    Y T:   tensor([628., 333.,  11., 356.,  12.])\n",
      "    Y P:   tensor([402.9190,  81.1176,  40.7881, 193.4623,  65.1444],\n",
      "       grad_fn=<AddBackward0>)\n",
      "    Thetas:  tensor([0.5000, 0.5422, 0.5099, 0.5053, 0.5018, 0.5395, 0.5074, 0.7958],\n",
      "       dtype=torch.float64)\n",
      "\n",
      "\n",
      "EPOCH:  80\n",
      "    Loss:  tensor(314621.7500, grad_fn=<MseLossBackward>)\n",
      "    MAE:   tensor(194.5752, grad_fn=<MeanBackward0>)\n",
      "    Y T:   tensor([ 48.,  11., 261., 344.,  19.])\n",
      "    Y P:   tensor([540.3820, 130.9274,  51.6056, 232.8710,  59.0432],\n",
      "       grad_fn=<AddBackward0>)\n",
      "    Thetas:  tensor([0.5000, 0.5427, 0.5099, 0.5053, 0.5018, 0.5401, 0.5074, 0.7984],\n",
      "       dtype=torch.float64)\n",
      "\n",
      "\n",
      "EPOCH:  81\n",
      "    Loss:  tensor(544870.1250, grad_fn=<MseLossBackward>)\n",
      "    MAE:   tensor(262.4601, grad_fn=<MeanBackward0>)\n",
      "    Y T:   tensor([359., 444., 304., 226., 652.])\n",
      "    Y P:   tensor([226.7016, 102.6781,  59.1869, 227.4726,  59.6057],\n",
      "       grad_fn=<AddBackward0>)\n",
      "    Thetas:  tensor([0.5000, 0.5428, 0.5100, 0.5053, 0.5018, 0.5402, 0.5074, 0.8021],\n",
      "       dtype=torch.float64)\n",
      "\n",
      "\n",
      "EPOCH:  82\n",
      "    Loss:  tensor(353415.8750, grad_fn=<MseLossBackward>)\n",
      "    MAE:   tensor(215.2087, grad_fn=<MeanBackward0>)\n",
      "    Y T:   tensor([463.,  46.,  10.,  19., 616.])\n",
      "    Y P:   tensor([264.4250, 132.4604,  85.2018, 227.4645, 108.6582],\n",
      "       grad_fn=<AddBackward0>)\n",
      "    Thetas:  tensor([0.5000, 0.5437, 0.5099, 0.5053, 0.5018, 0.5411, 0.5074, 0.8050],\n",
      "       dtype=torch.float64)\n",
      "\n",
      "\n",
      "EPOCH:  83\n",
      "    Loss:  tensor(95021.4688, grad_fn=<MseLossBackward>)\n",
      "    MAE:   tensor(117.0666, grad_fn=<MeanBackward0>)\n",
      "    Y T:   tensor([329., 267.,  51., 437.,  16.])\n",
      "    Y P:   tensor([365.2847, 125.9476,  81.7416, 219.1871, 175.4415],\n",
      "       grad_fn=<AddBackward0>)\n",
      "    Thetas:  tensor([0.5000, 0.5441, 0.5100, 0.5053, 0.5018, 0.5415, 0.5074, 0.8084],\n",
      "       dtype=torch.float64)\n",
      "\n",
      "\n",
      "EPOCH:  84\n",
      "    Loss:  tensor(125504.8203, grad_fn=<MseLossBackward>)\n",
      "    MAE:   tensor(110.2394, grad_fn=<MeanBackward0>)\n",
      "    Y T:   tensor([ 34., 321.,  92., 201., 126.])\n",
      "    Y P:   tensor([339.2554, 155.1345,  92.1065, 269.4015, 137.5683],\n",
      "       grad_fn=<AddBackward0>)\n",
      "    Thetas:  tensor([0.5000, 0.5449, 0.5101, 0.5053, 0.5018, 0.5423, 0.5075, 0.8121],\n",
      "       dtype=torch.float64)\n",
      "\n",
      "\n",
      "EPOCH:  85\n",
      "    Loss:  tensor(712365.0625, grad_fn=<MseLossBackward>)\n",
      "    MAE:   tensor(251.4791, grad_fn=<MeanBackward0>)\n",
      "    Y T:   tensor([ 30., 386.,  22., 185., 920.])\n",
      "    Y P:   tensor([183.0975, 142.5259,  68.1991, 207.7963, 128.1714],\n",
      "       grad_fn=<AddBackward0>)\n",
      "    Thetas:  tensor([0.5000, 0.5459, 0.5112, 0.5058, 0.5018, 0.5430, 0.5077, 0.8174],\n",
      "       dtype=torch.float64)\n",
      "\n",
      "\n",
      "EPOCH:  86\n",
      "    Loss:  tensor(1869933.6250, grad_fn=<MseLossBackward>)\n",
      "    MAE:   tensor(336.8655, grad_fn=<MeanBackward0>)\n",
      "    Y T:   tensor([ 217., 1584.,   30.,  115.,  213.])\n",
      "    Y P:   tensor([253.9893, 231.8645,  89.2401, 299.8639, 264.0986],\n",
      "       grad_fn=<AddBackward0>)\n",
      "    Thetas:  tensor([0.5000, 0.5453, 0.5106, 0.5056, 0.5018, 0.5425, 0.5076, 0.8168],\n",
      "       dtype=torch.float64)\n",
      "\n",
      "\n",
      "EPOCH:  87\n",
      "    Loss:  tensor(96220.0625, grad_fn=<MseLossBackward>)\n",
      "    MAE:   tensor(96.3098, grad_fn=<MeanBackward0>)\n",
      "    Y T:   tensor([ 80., 526., 205., 321., 385.])\n",
      "    Y P:   tensor([362.3499, 539.9792, 103.4599, 327.5437, 307.8641],\n",
      "       grad_fn=<AddBackward0>)\n",
      "    Thetas:  tensor([0.5000, 0.5454, 0.5106, 0.5056, 0.5018, 0.5426, 0.5076, 0.8204],\n",
      "       dtype=torch.float64)\n",
      "\n",
      "\n",
      "EPOCH:  88\n",
      "    Loss:  tensor(214669.3281, grad_fn=<MseLossBackward>)\n",
      "    MAE:   tensor(177.9118, grad_fn=<MeanBackward0>)\n",
      "    Y T:   tensor([ 25.,  26., 211., 163., 108.])\n",
      "    Y P:   tensor([188.0908, 408.2198,  98.0858, 243.5149, 258.8194],\n",
      "       grad_fn=<AddBackward0>)\n",
      "    Thetas:  tensor([0.5000, 0.5460, 0.5106, 0.5056, 0.5018, 0.5433, 0.5076, 0.8227],\n",
      "       dtype=torch.float64)\n",
      "\n",
      "\n",
      "EPOCH:  89\n",
      "    Loss:  tensor(2085276.1250, grad_fn=<MseLossBackward>)\n",
      "    MAE:   tensor(350.5678, grad_fn=<MeanBackward0>)\n",
      "    Y T:   tensor([1556.,  347.,  296.,  154.,  176.])\n",
      "    Y P:   tensor([128.2484, 284.1995,  95.0317, 201.8248, 189.4939],\n",
      "       grad_fn=<AddBackward0>)\n",
      "    Thetas:  tensor([0.5000, 0.5465, 0.5107, 0.5056, 0.5018, 0.5437, 0.5076, 0.8260],\n",
      "       dtype=torch.float64)\n",
      "\n",
      "\n",
      "EPOCH:  90\n",
      "    Loss:  tensor(822913.6875, grad_fn=<MseLossBackward>)\n",
      "    MAE:   tensor(303.2379, grad_fn=<MeanBackward0>)\n",
      "    Y T:   tensor([ 93.,  63., 943., 246., 124.])\n",
      "    Y P:   tensor([350.9411, 386.6402, 146.8398, 251.2629, 257.1848],\n",
      "       grad_fn=<AddBackward0>)\n",
      "    Thetas:  tensor([0.5000, 0.5470, 0.5109, 0.5056, 0.5018, 0.5442, 0.5077, 0.8303],\n",
      "       dtype=torch.float64)\n",
      "\n",
      "\n",
      "EPOCH:  91\n",
      "    Loss:  tensor(40983.2539, grad_fn=<MseLossBackward>)\n",
      "    MAE:   tensor(76.3518, grad_fn=<MeanBackward0>)\n",
      "    Y T:   tensor([306., 225., 178., 374., 281.])\n",
      "    Y P:   tensor([310.5332, 361.3846, 277.6794, 268.3289, 245.5094],\n",
      "       grad_fn=<AddBackward0>)\n",
      "    Thetas:  tensor([0.5000, 0.5467, 0.5109, 0.5056, 0.5018, 0.5440, 0.5076, 0.8337],\n",
      "       dtype=torch.float64)\n",
      "\n",
      "\n",
      "EPOCH:  92\n",
      "    Loss:  tensor(198137.2188, grad_fn=<MseLossBackward>)\n",
      "    MAE:   tensor(185.1666, grad_fn=<MeanBackward0>)\n",
      "    Y T:   tensor([ 23., 356.,  11.,   0.,  59.])\n",
      "    Y P:   tensor([268.9913, 297.6677, 220.3319, 258.3280, 212.8495],\n",
      "       grad_fn=<AddBackward0>)\n",
      "    Thetas:  tensor([0.5000, 0.5474, 0.5111, 0.5056, 0.5018, 0.5445, 0.5077, 0.8392],\n",
      "       dtype=torch.float64)\n",
      "\n",
      "\n",
      "EPOCH:  93\n",
      "    Loss:  tensor(74775.3906, grad_fn=<MseLossBackward>)\n",
      "    MAE:   tensor(119.6396, grad_fn=<MeanBackward0>)\n",
      "    Y T:   tensor([261., 344.,  48., 299.,   6.])\n",
      "    Y P:   tensor([165.9866, 201.6272, 131.6300, 154.5390, 138.7209],\n",
      "       grad_fn=<AddBackward0>)\n",
      "    Thetas:  tensor([0.5000, 0.5477, 0.5111, 0.5056, 0.5018, 0.5448, 0.5077, 0.8401],\n",
      "       dtype=torch.float64)\n",
      "\n",
      "\n",
      "EPOCH:  94\n",
      "    Loss:  tensor(313879.4062, grad_fn=<MseLossBackward>)\n",
      "    MAE:   tensor(207.1545, grad_fn=<MeanBackward0>)\n",
      "    Y T:   tensor([ 79., 123., 622.,  31., 335.])\n",
      "    Y P:   tensor([190.0923, 228.1507, 139.9116, 175.8585, 142.4174],\n",
      "       grad_fn=<AddBackward0>)\n",
      "    Thetas:  tensor([0.5000, 0.5489, 0.5114, 0.5056, 0.5018, 0.5458, 0.5078, 0.8456],\n",
      "       dtype=torch.float64)\n",
      "\n",
      "\n",
      "EPOCH:  95\n",
      "    Loss:  tensor(18322624., grad_fn=<MseLossBackward>)\n",
      "    MAE:   tensor(882.1891, grad_fn=<MeanBackward0>)\n",
      "    Y T:   tensor([ 233.,  321.,  237., 4488.,  138.])\n",
      "    Y P:   tensor([219.7125, 279.4360, 210.8687, 208.1018, 188.0639],\n",
      "       grad_fn=<AddBackward0>)\n",
      "    Thetas:  tensor([0.5000, 0.5483, 0.5117, 0.5056, 0.5018, 0.5453, 0.5077, 0.8508],\n",
      "       dtype=torch.float64)\n",
      "\n",
      "\n",
      "EPOCH:  96\n",
      "    Loss:  tensor(1851748.1250, grad_fn=<MseLossBackward>)\n",
      "    MAE:   tensor(449.2321, grad_fn=<MeanBackward0>)\n",
      "    Y T:   tensor([354., 465.,   0.,  84., 180.])\n",
      "    Y P:   tensor([ 597.6877,  545.8449,  499.1120, 1307.5762,  378.9400],\n",
      "       grad_fn=<AddBackward0>)\n",
      "    Thetas:  tensor([0.5000, 0.5489, 0.5116, 0.5056, 0.5018, 0.5459, 0.5077, 0.8531],\n",
      "       dtype=torch.float64)\n",
      "\n",
      "\n",
      "EPOCH:  97\n",
      "    Loss:  tensor(83963.0781, grad_fn=<MseLossBackward>)\n",
      "    MAE:   tensor(79.7710, grad_fn=<MeanBackward0>)\n",
      "    Y T:   tensor([ 88., 194., 155.,  32., 110.])\n",
      "    Y P:   tensor([130.8719, 202.5291,  87.5406, 310.3864, 108.3918],\n",
      "       grad_fn=<AddBackward0>)\n",
      "    Thetas:  tensor([0.5000, 0.5492, 0.5115, 0.5056, 0.5018, 0.5462, 0.5077, 0.8543],\n",
      "       dtype=torch.float64)\n",
      "\n",
      "\n",
      "EPOCH:  98\n",
      "    Loss:  tensor(580913.1875, grad_fn=<MseLossBackward>)\n",
      "    MAE:   tensor(272.6825, grad_fn=<MeanBackward0>)\n",
      "    Y T:   tensor([284., 706., 153., 767., 175.])\n",
      "    Y P:   tensor([111.7773, 184.1536,  76.0709, 249.9610,  99.6245],\n",
      "       grad_fn=<AddBackward0>)\n",
      "    Thetas:  tensor([0.5000, 0.5499, 0.5116, 0.5056, 0.5018, 0.5469, 0.5077, 0.8590],\n",
      "       dtype=torch.float64)\n",
      "\n",
      "\n",
      "EPOCH:  99\n",
      "    Loss:  tensor(310072.8125, grad_fn=<MseLossBackward>)\n",
      "    MAE:   tensor(165.5513, grad_fn=<MeanBackward0>)\n",
      "    Y T:   tensor([288., 603., 144.,  11., 153.])\n",
      "    Y P:   tensor([227.3970, 375.6313, 146.2487, 514.5296, 187.0064],\n",
      "       grad_fn=<AddBackward0>)\n",
      "    Thetas:  tensor([0.5000, 0.5495, 0.5116, 0.5056, 0.5018, 0.5465, 0.5077, 0.8603],\n",
      "       dtype=torch.float64)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "losses_no_circ, maes_no_circ = [], []\n",
    "\n",
    "n_vals = 5\n",
    "n_dim = 5\n",
    "lr = 1e-6\n",
    "theta_lr = .10 #00000000\n",
    "thetas = [.5] * 8\n",
    "batch_size = 5\n",
    "\n",
    "model = QuantumCicuitNet(n_vals, n_dim, batch_size)\n",
    "\n",
    "criterion = torch.nn.MSELoss(reduction='sum')\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = lr)\n",
    "\n",
    "\n",
    "\n",
    "for i in range(0, 100):\n",
    "\n",
    "    print(\"EPOCH: \", i)\n",
    "\n",
    "    batch_obs = random.sample(range(0, len(X)), 5)\n",
    "\n",
    "    x = np.array([list(i)[0:5] for i in X[batch_obs]])\n",
    "    Y = torch.tensor(y.detach().numpy()[batch_obs])\n",
    "\n",
    "    y_pred, grad = model(torch.tensor(x), thetas)\n",
    "    loss = criterion(y_pred, Y)\n",
    "    cur_losses.append(loss)\n",
    "    \n",
    "\n",
    "    print(\"    Loss: \", loss)\n",
    "    print(\"    MAE:  \", mae(y_pred, Y))\n",
    "    print(\"    Y T:  \", Y)\n",
    "    print(\"    Y P:  \", y_pred)\n",
    "\n",
    "    cur_maes.append(mae(y_pred, Y))\n",
    "\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    thetas = [i.item() for i in list(torch.tensor(thetas) + (grad * theta_lr))]\n",
    "\n",
    "    print(\"    Thetas: \", torch.tensor(thetas) + grad * theta_lr)\n",
    "\n",
    "    print(\"\\n\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[0.5291187428001014,\n",
       " 0.5182355232192323,\n",
       " 0.5036585542213845,\n",
       " 0.5017569469706846,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5]"
      ]
     },
     "metadata": {},
     "execution_count": 71
    }
   ],
   "source": [
    "thetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = [[i for i in range(0, 200)][i:i + 5] for i in range(0, len([i for i in range(0, 200)]), 5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0, 1, 2, 3, 4]\n",
      "<ipython-input-145-269fe5669e4e>:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  mean_grads = torch.reshape(torch.tensor(mean_grads), (len(vals), len(thetas)))\n",
      "\n",
      "[5, 6, 7, 8, 9]\n",
      "\n",
      "[10, 11, 12, 13, 14]\n",
      "\n",
      "[15, 16, 17, 18, 19]\n",
      "\n",
      "[20, 21, 22, 23, 24]\n",
      "\n",
      "[25, 26, 27, 28, 29]\n",
      "\n",
      "[30, 31, 32, 33, 34]\n",
      "\n",
      "[35, 36, 37, 38, 39]\n",
      "\n",
      "[40, 41, 42, 43, 44]\n",
      "\n",
      "[45, 46, 47, 48, 49]\n",
      "\n",
      "[50, 51, 52, 53, 54]\n",
      "\n",
      "[55, 56, 57, 58, 59]\n",
      "\n",
      "[60, 61, 62, 63, 64]\n",
      "\n",
      "[65, 66, 67, 68, 69]\n",
      "\n",
      "[70, 71, 72, 73, 74]\n",
      "\n",
      "[75, 76, 77, 78, 79]\n",
      "\n",
      "[80, 81, 82, 83, 84]\n",
      "\n",
      "[85, 86, 87, 88, 89]\n",
      "\n",
      "[90, 91, 92, 93, 94]\n",
      "\n",
      "[95, 96, 97, 98, 99]\n",
      "\n",
      "[100, 101, 102, 103, 104]\n",
      "\n",
      "[105, 106, 107, 108, 109]\n",
      "\n",
      "[110, 111, 112, 113, 114]\n",
      "\n",
      "[115, 116, 117, 118, 119]\n",
      "\n",
      "[120, 121, 122, 123, 124]\n",
      "\n",
      "[125, 126, 127, 128, 129]\n",
      "\n",
      "[130, 131, 132, 133, 134]\n",
      "\n",
      "[135, 136, 137, 138, 139]\n",
      "\n",
      "[140, 141, 142, 143, 144]\n",
      "\n",
      "[145, 146, 147, 148, 149]\n",
      "\n",
      "[150, 151, 152, 153, 154]\n",
      "\n",
      "[155, 156, 157, 158, 159]\n",
      "\n",
      "[160, 161, 162, 163, 164]\n",
      "\n",
      "[165, 166, 167, 168, 169]\n",
      "\n",
      "[170, 171, 172, 173, 174]\n",
      "\n",
      "[175, 176, 177, 178, 179]\n",
      "\n",
      "[180, 181, 182, 183, 184]\n",
      "\n",
      "[185, 186, 187, 188, 189]\n",
      "\n",
      "[190, 191, 192, 193, 194]\n",
      "\n",
      "[195, 196, 197, 198, 199]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds_df = pd.DataFrame()\n",
    "preds = []\n",
    "trues = []\n",
    "\n",
    "for i in obs:\n",
    "    print(i)\n",
    "    inp = np.array([list(i)[0:5] for i in X[i]])\n",
    "    ys = torch.tensor(y.detach().numpy()[i])\n",
    "    pred, _ = model(torch.tensor(inp), thetas)\n",
    "    \n",
    "    preds += list(pred.detach().numpy())\n",
    "    trues += ys\n",
    "    # preds += list(pred.detach().numpy())\n",
    "\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[738.5281,\n",
       " 273.87335,\n",
       " 775.1601,\n",
       " 902.008,\n",
       " 211.5946,\n",
       " 729.35364,\n",
       " 270.48932,\n",
       " 769.1065,\n",
       " 893.63947,\n",
       " 210.57365]"
      ]
     },
     "metadata": {},
     "execution_count": 84
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([ 337.,  204.,  320.,   61., 2063.])"
      ]
     },
     "metadata": {},
     "execution_count": 85
    }
   ],
   "source": [
    "ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   true        pred\n",
       "0   961  211.008377\n",
       "1   154  371.236877\n",
       "2   905  130.940079\n",
       "3   225  391.162872\n",
       "4  1071  158.423676"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>true</th>\n      <th>pred</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>961</td>\n      <td>211.008377</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>154</td>\n      <td>371.236877</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>905</td>\n      <td>130.940079</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>225</td>\n      <td>391.162872</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1071</td>\n      <td>158.423676</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 162
    }
   ],
   "source": [
    "preds_df['true'] = trues\n",
    "preds_df['true'] = preds_df['true'].astype(int)\n",
    "preds_df['pred'] = preds\n",
    "preds_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "454.9825577163696"
      ]
     },
     "metadata": {},
     "execution_count": 163
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "mean_absolute_error(preds_df['true'], preds_df['pred'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.719914099680905"
      ]
     },
     "metadata": {},
     "execution_count": 164
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "\n",
    "mean_absolute_percentage_error(preds_df['true'], preds_df['pred'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "71.99140996809051"
      ]
     },
     "metadata": {},
     "execution_count": 170
    }
   ],
   "source": [
    "0.719914099680905*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "-0.3868732918629465"
      ]
     },
     "metadata": {},
     "execution_count": 165
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "r2_score(preds_df['true'], preds_df['pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "394.060453453064"
      ]
     },
     "metadata": {},
     "execution_count": 166
    }
   ],
   "source": [
    "def allocation_error(ytruelist, ypredlist):\n",
    "    return abs((sum(ytruelist) - sum(ypredlist)) / len(ypredlist))\n",
    "\n",
    "\n",
    "allocation_error(preds_df['true'], preds_df['pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "78812.0906906128"
      ]
     },
     "metadata": {},
     "execution_count": 167
    }
   ],
   "source": [
    "def quantity_error(ytruelist, ypredlist): \n",
    "    return abs(sum(ytruelist) - sum(ypredlist))\n",
    "\n",
    "\n",
    "quantity_error(preds_df['true'], preds_df['pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_df.to_csv(\"./preds_df2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fdb2df37040>"
      ]
     },
     "metadata": {},
     "execution_count": 169
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"248.518125pt\" version=\"1.1\" viewBox=\"0 0 375.571359 248.518125\" width=\"375.571359pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <metadata>\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2021-03-24T22:43:44.300877</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.3.4, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 248.518125 \nL 375.571359 248.518125 \nL 375.571359 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 33.2875 224.64 \nL 368.0875 224.64 \nL 368.0875 7.2 \nL 33.2875 7.2 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"PathCollection_1\">\n    <defs>\n     <path d=\"M 0 3 \nC 0.795609 3 1.55874 2.683901 2.12132 2.12132 \nC 2.683901 1.55874 3 0.795609 3 0 \nC 3 -0.795609 2.683901 -1.55874 2.12132 -2.12132 \nC 1.55874 -2.683901 0.795609 -3 0 -3 \nC -0.795609 -3 -1.55874 -2.683901 -2.12132 -2.12132 \nC -2.683901 -1.55874 -3 -0.795609 -3 0 \nC -3 0.795609 -2.683901 1.55874 -2.12132 2.12132 \nC -1.55874 2.683901 -0.795609 3 0 3 \nz\n\" id=\"m9f1b30142a\" style=\"stroke:#1f77b4;\"/>\n    </defs>\n    <g clip-path=\"url(#p409595c46d)\">\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"106.391548\" xlink:href=\"#m9f1b30142a\" y=\"154.828506\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"56.589955\" xlink:href=\"#m9f1b30142a\" y=\"41.188465\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"102.935675\" xlink:href=\"#m9f1b30142a\" y=\"211.615935\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"60.971508\" xlink:href=\"#m9f1b30142a\" y=\"27.056205\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"113.179869\" xlink:href=\"#m9f1b30142a\" y=\"192.123541\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"67.883253\" xlink:href=\"#m9f1b30142a\" y=\"153.498134\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"59.675556\" xlink:href=\"#m9f1b30142a\" y=\"38.596831\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"66.834149\" xlink:href=\"#m9f1b30142a\" y=\"211.135293\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"50.850738\" xlink:href=\"#m9f1b30142a\" y=\"24.426607\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"174.398183\" xlink:href=\"#m9f1b30142a\" y=\"190.915751\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"54.800307\" xlink:href=\"#m9f1b30142a\" y=\"154.841438\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"57.577347\" xlink:href=\"#m9f1b30142a\" y=\"41.211213\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"70.413446\" xlink:href=\"#m9f1b30142a\" y=\"211.623965\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"66.710725\" xlink:href=\"#m9f1b30142a\" y=\"27.08023\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"95.036538\" xlink:href=\"#m9f1b30142a\" y=\"192.133249\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"59.49042\" xlink:href=\"#m9f1b30142a\" y=\"154.848635\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"73.437334\" xlink:href=\"#m9f1b30142a\" y=\"41.223875\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"58.626452\" xlink:href=\"#m9f1b30142a\" y=\"211.628435\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"55.294003\" xlink:href=\"#m9f1b30142a\" y=\"27.093563\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"65.846757\" xlink:href=\"#m9f1b30142a\" y=\"192.138649\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"76.646359\" xlink:href=\"#m9f1b30142a\" y=\"153.455473\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"75.720679\" xlink:href=\"#m9f1b30142a\" y=\"39.125253\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"57.145363\" xlink:href=\"#m9f1b30142a\" y=\"211.581142\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"94.727978\" xlink:href=\"#m9f1b30142a\" y=\"25.003035\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"50.60389\" xlink:href=\"#m9f1b30142a\" y=\"191.088223\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"60.601236\" xlink:href=\"#m9f1b30142a\" y=\"154.861611\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"60.10754\" xlink:href=\"#m9f1b30142a\" y=\"41.246688\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"52.023266\" xlink:href=\"#m9f1b30142a\" y=\"211.636486\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"63.563412\" xlink:href=\"#m9f1b30142a\" y=\"27.117631\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"66.031893\" xlink:href=\"#m9f1b30142a\" y=\"192.148378\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"59.305284\" xlink:href=\"#m9f1b30142a\" y=\"153.809799\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"111.760493\" xlink:href=\"#m9f1b30142a\" y=\"38.665335\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"61.218356\" xlink:href=\"#m9f1b30142a\" y=\"210.72941\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"72.573366\" xlink:href=\"#m9f1b30142a\" y=\"23.993679\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"75.47383\" xlink:href=\"#m9f1b30142a\" y=\"191.06501\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"54.553459\" xlink:href=\"#m9f1b30142a\" y=\"154.874597\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"62.822868\" xlink:href=\"#m9f1b30142a\" y=\"41.269544\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"56.157971\" xlink:href=\"#m9f1b30142a\" y=\"211.644538\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"55.479139\" xlink:href=\"#m9f1b30142a\" y=\"27.141656\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"56.775091\" xlink:href=\"#m9f1b30142a\" y=\"192.158118\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"63.625124\" xlink:href=\"#m9f1b30142a\" y=\"149.715776\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"65.291349\" xlink:href=\"#m9f1b30142a\" y=\"31.83951\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"68.191813\" xlink:href=\"#m9f1b30142a\" y=\"207.621746\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"95.221674\" xlink:href=\"#m9f1b30142a\" y=\"17.083636\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"77.572039\" xlink:href=\"#m9f1b30142a\" y=\"188.29256\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"60.786372\" xlink:href=\"#m9f1b30142a\" y=\"154.625072\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"96.579338\" xlink:href=\"#m9f1b30142a\" y=\"41.263051\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"140.086306\" xlink:href=\"#m9f1b30142a\" y=\"212.492926\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"147.923731\" xlink:href=\"#m9f1b30142a\" y=\"27.283209\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"120.091614\" xlink:href=\"#m9f1b30142a\" y=\"191.964619\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"79.299975\" xlink:href=\"#m9f1b30142a\" y=\"156.350104\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"64.427381\" xlink:href=\"#m9f1b30142a\" y=\"43.86542\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"105.280732\" xlink:href=\"#m9f1b30142a\" y=\"212.560305\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"130.644368\" xlink:href=\"#m9f1b30142a\" y=\"29.877051\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"107.810924\" xlink:href=\"#m9f1b30142a\" y=\"193.265219\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"85.28604\" xlink:href=\"#m9f1b30142a\" y=\"156.358069\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"119.597918\" xlink:href=\"#m9f1b30142a\" y=\"43.879446\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"102.441979\" xlink:href=\"#m9f1b30142a\" y=\"212.56525\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"121.20243\" xlink:href=\"#m9f1b30142a\" y=\"29.891812\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"211.980798\" xlink:href=\"#m9f1b30142a\" y=\"193.271193\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"82.138728\" xlink:href=\"#m9f1b30142a\" y=\"156.366024\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"131.199776\" xlink:href=\"#m9f1b30142a\" y=\"43.893471\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"98.307274\" xlink:href=\"#m9f1b30142a\" y=\"212.570207\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"73.992742\" xlink:href=\"#m9f1b30142a\" y=\"29.906574\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"161.994069\" xlink:href=\"#m9f1b30142a\" y=\"193.277167\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"173.102231\" xlink:href=\"#m9f1b30142a\" y=\"156.374021\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"68.685509\" xlink:href=\"#m9f1b30142a\" y=\"43.907475\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"105.774428\" xlink:href=\"#m9f1b30142a\" y=\"212.575152\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"76.769783\" xlink:href=\"#m9f1b30142a\" y=\"29.921378\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"81.398183\" xlink:href=\"#m9f1b30142a\" y=\"193.283151\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"83.619816\" xlink:href=\"#m9f1b30142a\" y=\"156.381986\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"78.867991\" xlink:href=\"#m9f1b30142a\" y=\"43.921522\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"89.914441\" xlink:href=\"#m9f1b30142a\" y=\"212.580098\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"68.315237\" xlink:href=\"#m9f1b30142a\" y=\"29.93614\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"156.748548\" xlink:href=\"#m9f1b30142a\" y=\"193.289136\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"168.905815\" xlink:href=\"#m9f1b30142a\" y=\"156.389962\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"144.652994\" xlink:href=\"#m9f1b30142a\" y=\"43.935548\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"79.114839\" xlink:href=\"#m9f1b30142a\" y=\"212.585055\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"110.341116\" xlink:href=\"#m9f1b30142a\" y=\"29.950944\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"112.069053\" xlink:href=\"#m9f1b30142a\" y=\"193.295131\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"91.457241\" xlink:href=\"#m9f1b30142a\" y=\"156.397949\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"90.778409\" xlink:href=\"#m9f1b30142a\" y=\"43.949616\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"113.241581\" xlink:href=\"#m9f1b30142a\" y=\"212.590011\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"74.23959\" xlink:href=\"#m9f1b30142a\" y=\"29.965749\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"100.220347\" xlink:href=\"#m9f1b30142a\" y=\"193.301116\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"91.704089\" xlink:href=\"#m9f1b30142a\" y=\"156.405946\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"55.602563\" xlink:href=\"#m9f1b30142a\" y=\"43.963685\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"134.655649\" xlink:href=\"#m9f1b30142a\" y=\"212.594968\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"80.534215\" xlink:href=\"#m9f1b30142a\" y=\"29.980575\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"64.797653\" xlink:href=\"#m9f1b30142a\" y=\"193.307111\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"108.551468\" xlink:href=\"#m9f1b30142a\" y=\"157.410562\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"78.621143\" xlink:href=\"#m9f1b30142a\" y=\"45.639207\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"116.142045\" xlink:href=\"#m9f1b30142a\" y=\"213.355978\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"270.66892\" xlink:href=\"#m9f1b30142a\" y=\"31.677351\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"82.077016\" xlink:href=\"#m9f1b30142a\" y=\"193.988082\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"352.869318\" xlink:href=\"#m9f1b30142a\" y=\"158.017834\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"77.942311\" xlink:href=\"#m9f1b30142a\" y=\"46.799466\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"64.242245\" xlink:href=\"#m9f1b30142a\" y=\"213.595385\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"71.277414\" xlink:href=\"#m9f1b30142a\" y=\"32.968753\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"60.971508\" xlink:href=\"#m9f1b30142a\" y=\"194.516536\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"81.151335\" xlink:href=\"#m9f1b30142a\" y=\"158.026556\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"151.996724\" xlink:href=\"#m9f1b30142a\" y=\"46.814833\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"74.609862\" xlink:href=\"#m9f1b30142a\" y=\"213.600806\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"92.814905\" xlink:href=\"#m9f1b30142a\" y=\"32.984943\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"107.008668\" xlink:href=\"#m9f1b30142a\" y=\"194.523094\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"60.971508\" xlink:href=\"#m9f1b30142a\" y=\"158.03529\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"63.131428\" xlink:href=\"#m9f1b30142a\" y=\"46.830201\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"59.613844\" xlink:href=\"#m9f1b30142a\" y=\"213.606228\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"64.921077\" xlink:href=\"#m9f1b30142a\" y=\"33.001132\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"69.91975\" xlink:href=\"#m9f1b30142a\" y=\"194.529641\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"120.955582\" xlink:href=\"#m9f1b30142a\" y=\"158.044045\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"120.89387\" xlink:href=\"#m9f1b30142a\" y=\"46.84559\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"60.539524\" xlink:href=\"#m9f1b30142a\" y=\"213.61165\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"59.984116\" xlink:href=\"#m9f1b30142a\" y=\"33.017322\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"67.759829\" xlink:href=\"#m9f1b30142a\" y=\"194.536199\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"60.971508\" xlink:href=\"#m9f1b30142a\" y=\"158.052778\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"55.355715\" xlink:href=\"#m9f1b30142a\" y=\"46.860957\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"62.88458\" xlink:href=\"#m9f1b30142a\" y=\"213.617072\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"79.114839\" xlink:href=\"#m9f1b30142a\" y=\"33.033512\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"112.562749\" xlink:href=\"#m9f1b30142a\" y=\"194.542758\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"75.967527\" xlink:href=\"#m9f1b30142a\" y=\"158.061523\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"70.351734\" xlink:href=\"#m9f1b30142a\" y=\"46.876346\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"71.277414\" xlink:href=\"#m9f1b30142a\" y=\"213.622505\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"149.528243\" xlink:href=\"#m9f1b30142a\" y=\"33.049745\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"67.451269\" xlink:href=\"#m9f1b30142a\" y=\"194.549316\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"67.266133\" xlink:href=\"#m9f1b30142a\" y=\"158.070278\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"80.657639\" xlink:href=\"#m9f1b30142a\" y=\"46.891735\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"56.096259\" xlink:href=\"#m9f1b30142a\" y=\"213.627927\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"100.590619\" xlink:href=\"#m9f1b30142a\" y=\"33.065979\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"80.719351\" xlink:href=\"#m9f1b30142a\" y=\"194.555885\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"60.230964\" xlink:href=\"#m9f1b30142a\" y=\"158.079033\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"61.65034\" xlink:href=\"#m9f1b30142a\" y=\"46.907146\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"176.496392\" xlink:href=\"#m9f1b30142a\" y=\"213.63337\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"76.831495\" xlink:href=\"#m9f1b30142a\" y=\"33.082212\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"249.748548\" xlink:href=\"#m9f1b30142a\" y=\"194.562454\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"60.477812\" xlink:href=\"#m9f1b30142a\" y=\"158.087777\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"69.981462\" xlink:href=\"#m9f1b30142a\" y=\"46.922535\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"66.834149\" xlink:href=\"#m9f1b30142a\" y=\"213.638803\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"137.062417\" xlink:href=\"#m9f1b30142a\" y=\"33.098445\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"57.021939\" xlink:href=\"#m9f1b30142a\" y=\"194.569023\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"73.992742\" xlink:href=\"#m9f1b30142a\" y=\"158.096543\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"55.972835\" xlink:href=\"#m9f1b30142a\" y=\"46.937946\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"63.316564\" xlink:href=\"#m9f1b30142a\" y=\"213.644246\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"64.118821\" xlink:href=\"#m9f1b30142a\" y=\"33.114678\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"64.550805\" xlink:href=\"#m9f1b30142a\" y=\"194.575592\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"152.120148\" xlink:href=\"#m9f1b30142a\" y=\"158.105309\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"92.444633\" xlink:href=\"#m9f1b30142a\" y=\"46.953356\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"62.514308\" xlink:href=\"#m9f1b30142a\" y=\"213.649668\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"61.465204\" xlink:href=\"#m9f1b30142a\" y=\"33.130911\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"81.768456\" xlink:href=\"#m9f1b30142a\" y=\"194.582172\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"68.932357\" xlink:href=\"#m9f1b30142a\" y=\"158.114075\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"80.410791\" xlink:href=\"#m9f1b30142a\" y=\"46.968789\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"55.417427\" xlink:href=\"#m9f1b30142a\" y=\"213.655112\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"208.092941\" xlink:href=\"#m9f1b30142a\" y=\"33.147144\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"67.389557\" xlink:href=\"#m9f1b30142a\" y=\"194.588752\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"63.254852\" xlink:href=\"#m9f1b30142a\" y=\"158.122851\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"104.046491\" xlink:href=\"#m9f1b30142a\" y=\"46.984221\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"82.015304\" xlink:href=\"#m9f1b30142a\" y=\"213.660566\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"82.694136\" xlink:href=\"#m9f1b30142a\" y=\"33.163421\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"176.558104\" xlink:href=\"#m9f1b30142a\" y=\"194.595331\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"75.226982\" xlink:href=\"#m9f1b30142a\" y=\"158.131628\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"144.83813\" xlink:href=\"#m9f1b30142a\" y=\"46.999675\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"93.740586\" xlink:href=\"#m9f1b30142a\" y=\"213.66601\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"64.797653\" xlink:href=\"#m9f1b30142a\" y=\"33.179697\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"156.563412\" xlink:href=\"#m9f1b30142a\" y=\"194.601911\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"57.083651\" xlink:href=\"#m9f1b30142a\" y=\"159.469846\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"103.984779\" xlink:href=\"#m9f1b30142a\" y=\"49.445146\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"64.489093\" xlink:href=\"#m9f1b30142a\" y=\"214.707875\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"67.821541\" xlink:href=\"#m9f1b30142a\" y=\"35.787802\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"68.315237\" xlink:href=\"#m9f1b30142a\" y=\"195.604687\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"60.971508\" xlink:href=\"#m9f1b30142a\" y=\"159.840969\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"80.163943\" xlink:href=\"#m9f1b30142a\" y=\"50.006964\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"62.26746\" xlink:href=\"#m9f1b30142a\" y=\"214.726906\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"59.737268\" xlink:href=\"#m9f1b30142a\" y=\"36.348561\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"58.56474\" xlink:href=\"#m9f1b30142a\" y=\"195.88446\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"54.800307\" xlink:href=\"#m9f1b30142a\" y=\"159.85046\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"48.505682\" xlink:href=\"#m9f1b30142a\" y=\"50.02363\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"83.558104\" xlink:href=\"#m9f1b30142a\" y=\"214.732799\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"51.714706\" xlink:href=\"#m9f1b30142a\" y=\"36.366157\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"58.194467\" xlink:href=\"#m9f1b30142a\" y=\"195.891592\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"77.757175\" xlink:href=\"#m9f1b30142a\" y=\"159.859951\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"73.869318\" xlink:href=\"#m9f1b30142a\" y=\"50.04034\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"60.662948\" xlink:href=\"#m9f1b30142a\" y=\"214.73868\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"96.887898\" xlink:href=\"#m9f1b30142a\" y=\"36.383732\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"94.604554\" xlink:href=\"#m9f1b30142a\" y=\"195.898702\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"72.203094\" xlink:href=\"#m9f1b30142a\" y=\"159.869442\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"52.331826\" xlink:href=\"#m9f1b30142a\" y=\"50.057027\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"55.540851\" xlink:href=\"#m9f1b30142a\" y=\"214.744578\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"73.00535\" xlink:href=\"#m9f1b30142a\" y=\"36.401329\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"87.877945\" xlink:href=\"#m9f1b30142a\" y=\"195.905823\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"55.479139\" xlink:href=\"#m9f1b30142a\" y=\"159.878932\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"52.331826\" xlink:href=\"#m9f1b30142a\" y=\"50.073758\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"63.933684\" xlink:href=\"#m9f1b30142a\" y=\"214.750466\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"53.134083\" xlink:href=\"#m9f1b30142a\" y=\"36.418926\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"71.46255\" xlink:href=\"#m9f1b30142a\" y=\"195.912955\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"79.608535\" xlink:href=\"#m9f1b30142a\" y=\"159.888434\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"79.546823\" xlink:href=\"#m9f1b30142a\" y=\"50.090446\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"54.244899\" xlink:href=\"#m9f1b30142a\" y=\"214.756364\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"69.487765\" xlink:href=\"#m9f1b30142a\" y=\"36.436544\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"59.243572\" xlink:href=\"#m9f1b30142a\" y=\"195.920076\"/>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"m81571169d6\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"47.086306\" xlink:href=\"#m81571169d6\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <g transform=\"translate(43.905056 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"108.798316\" xlink:href=\"#m81571169d6\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 1000 -->\n      <g transform=\"translate(96.073316 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 12.40625 8.296875 \nL 28.515625 8.296875 \nL 28.515625 63.921875 \nL 10.984375 60.40625 \nL 10.984375 69.390625 \nL 28.421875 72.90625 \nL 38.28125 72.90625 \nL 38.28125 8.296875 \nL 54.390625 8.296875 \nL 54.390625 0 \nL 12.40625 0 \nz\n\" id=\"DejaVuSans-49\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"170.510327\" xlink:href=\"#m81571169d6\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 2000 -->\n      <g transform=\"translate(157.785327 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 19.1875 8.296875 \nL 53.609375 8.296875 \nL 53.609375 0 \nL 7.328125 0 \nL 7.328125 8.296875 \nQ 12.9375 14.109375 22.625 23.890625 \nQ 32.328125 33.6875 34.8125 36.53125 \nQ 39.546875 41.84375 41.421875 45.53125 \nQ 43.3125 49.21875 43.3125 52.78125 \nQ 43.3125 58.59375 39.234375 62.25 \nQ 35.15625 65.921875 28.609375 65.921875 \nQ 23.96875 65.921875 18.8125 64.3125 \nQ 13.671875 62.703125 7.8125 59.421875 \nL 7.8125 69.390625 \nQ 13.765625 71.78125 18.9375 73 \nQ 24.125 74.21875 28.421875 74.21875 \nQ 39.75 74.21875 46.484375 68.546875 \nQ 53.21875 62.890625 53.21875 53.421875 \nQ 53.21875 48.921875 51.53125 44.890625 \nQ 49.859375 40.875 45.40625 35.40625 \nQ 44.1875 33.984375 37.640625 27.21875 \nQ 31.109375 20.453125 19.1875 8.296875 \nz\n\" id=\"DejaVuSans-50\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"232.222337\" xlink:href=\"#m81571169d6\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 3000 -->\n      <g transform=\"translate(219.497337 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 40.578125 39.3125 \nQ 47.65625 37.796875 51.625 33 \nQ 55.609375 28.21875 55.609375 21.1875 \nQ 55.609375 10.40625 48.1875 4.484375 \nQ 40.765625 -1.421875 27.09375 -1.421875 \nQ 22.515625 -1.421875 17.65625 -0.515625 \nQ 12.796875 0.390625 7.625 2.203125 \nL 7.625 11.71875 \nQ 11.71875 9.328125 16.59375 8.109375 \nQ 21.484375 6.890625 26.8125 6.890625 \nQ 36.078125 6.890625 40.9375 10.546875 \nQ 45.796875 14.203125 45.796875 21.1875 \nQ 45.796875 27.640625 41.28125 31.265625 \nQ 36.765625 34.90625 28.71875 34.90625 \nL 20.21875 34.90625 \nL 20.21875 43.015625 \nL 29.109375 43.015625 \nQ 36.375 43.015625 40.234375 45.921875 \nQ 44.09375 48.828125 44.09375 54.296875 \nQ 44.09375 59.90625 40.109375 62.90625 \nQ 36.140625 65.921875 28.71875 65.921875 \nQ 24.65625 65.921875 20.015625 65.03125 \nQ 15.375 64.15625 9.8125 62.3125 \nL 9.8125 71.09375 \nQ 15.4375 72.65625 20.34375 73.4375 \nQ 25.25 74.21875 29.59375 74.21875 \nQ 40.828125 74.21875 47.359375 69.109375 \nQ 53.90625 64.015625 53.90625 55.328125 \nQ 53.90625 49.265625 50.4375 45.09375 \nQ 46.96875 40.921875 40.578125 39.3125 \nz\n\" id=\"DejaVuSans-51\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-51\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"293.934348\" xlink:href=\"#m81571169d6\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 4000 -->\n      <g transform=\"translate(281.209348 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 37.796875 64.3125 \nL 12.890625 25.390625 \nL 37.796875 25.390625 \nz\nM 35.203125 72.90625 \nL 47.609375 72.90625 \nL 47.609375 25.390625 \nL 58.015625 25.390625 \nL 58.015625 17.1875 \nL 47.609375 17.1875 \nL 47.609375 0 \nL 37.796875 0 \nL 37.796875 17.1875 \nL 4.890625 17.1875 \nL 4.890625 26.703125 \nz\n\" id=\"DejaVuSans-52\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-52\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"355.646359\" xlink:href=\"#m81571169d6\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 5000 -->\n      <g transform=\"translate(342.921359 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 10.796875 72.90625 \nL 49.515625 72.90625 \nL 49.515625 64.59375 \nL 19.828125 64.59375 \nL 19.828125 46.734375 \nQ 21.96875 47.46875 24.109375 47.828125 \nQ 26.265625 48.1875 28.421875 48.1875 \nQ 40.625 48.1875 47.75 41.5 \nQ 54.890625 34.8125 54.890625 23.390625 \nQ 54.890625 11.625 47.5625 5.09375 \nQ 40.234375 -1.421875 26.90625 -1.421875 \nQ 22.3125 -1.421875 17.546875 -0.640625 \nQ 12.796875 0.140625 7.71875 1.703125 \nL 7.71875 11.625 \nQ 12.109375 9.234375 16.796875 8.0625 \nQ 21.484375 6.890625 26.703125 6.890625 \nQ 35.15625 6.890625 40.078125 11.328125 \nQ 45.015625 15.765625 45.015625 23.390625 \nQ 45.015625 31 40.078125 35.4375 \nQ 35.15625 39.890625 26.703125 39.890625 \nQ 22.75 39.890625 18.8125 39.015625 \nQ 14.890625 38.140625 10.796875 36.28125 \nz\n\" id=\"DejaVuSans-53\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_7\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"m4703beebe3\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"33.2875\" xlink:href=\"#m4703beebe3\" y=\"198.097927\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 150 -->\n      <g transform=\"translate(7.2 201.897146)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_8\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"33.2875\" xlink:href=\"#m4703beebe3\" y=\"162.636058\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 200 -->\n      <g transform=\"translate(7.2 166.435277)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_9\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"33.2875\" xlink:href=\"#m4703beebe3\" y=\"127.174189\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 250 -->\n      <g transform=\"translate(7.2 130.973408)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_10\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"33.2875\" xlink:href=\"#m4703beebe3\" y=\"91.712321\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 300 -->\n      <g transform=\"translate(7.2 95.51154)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-51\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_11\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"33.2875\" xlink:href=\"#m4703beebe3\" y=\"56.250452\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 350 -->\n      <g transform=\"translate(7.2 60.049671)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-51\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_12\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"33.2875\" xlink:href=\"#m4703beebe3\" y=\"20.788583\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 400 -->\n      <g transform=\"translate(7.2 24.587802)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-52\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 33.2875 224.64 \nL 33.2875 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 368.0875 224.64 \nL 368.0875 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 33.2875 224.64 \nL 368.0875 224.64 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 33.2875 7.2 \nL 368.0875 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p409595c46d\">\n   <rect height=\"217.44\" width=\"334.8\" x=\"33.2875\" y=\"7.2\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "plt.scatter(preds_df['true'], preds_df['pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}