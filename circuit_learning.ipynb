{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.6 64-bit ('qnn': conda)",
   "metadata": {
    "interpreter": {
     "hash": "4978dc1864a661fcd348fb688fbace178c7388184fc0914a9258717a7a8394e1"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pennylane as qml\n",
    "import matplotlib.pyplot as plt\n",
    "from pennylane import numpy as np\n",
    "from scipy.linalg import expm\n",
    "\n",
    "from math import pi\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import torch\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([0.9704776 , 0.68989013, 0.60582016, 0.94275467, 0.99500417], requires_grad=True)"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "n_vals = 5\n",
    "\n",
    "dev = qml.device('default.qubit', wires = n_vals)\n",
    "\n",
    "@qml.qnode(dev)\n",
    "def rotation_circuit(vals, theta):\n",
    "\n",
    "    # Apply Hadamards\n",
    "    for hadamard_wire in range(len(vals)):\n",
    "        qml.Hadamard(wires = hadamard_wire)\n",
    "\n",
    "    # Apply value dependent Z-axis rotations\n",
    "    for rotation_val in range(len(vals)):\n",
    "        qml.RZ(vals[rotation_val], wires = rotation_val)\n",
    "\n",
    "    # Random CNOT\n",
    "    qml.CNOT(wires = [1,0])\n",
    "\n",
    "    # Parametized rotation <- this is what is being trained\n",
    "    qml.RY(theta, wires=0)\n",
    "\n",
    "    # Get expected values & return them\n",
    "    expected_values = [qml.expval(qml.PauliX(wire)) for wire in range(len(vals))]\n",
    "    return expected_values\n",
    "\n",
    "\n",
    "rotation_circuit([.14, .80, .92, .34, .1], .2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class QuantumLayer():\n",
    "\n",
    "#     def __init__(self, n_vals):\n",
    "\n",
    "#         self.devX = qml.device('default.qubit', wires = n_vals)\n",
    "#         self.devY = qml.device('default.qubit', wires = n_vals)\n",
    "#         self.devZ = qml.device('default.qubit', wires = n_vals)\n",
    "\n",
    "#         @qml.qnode(self.devX)\n",
    "#         def rotation_circuitX(vals, theta):\n",
    "\n",
    "#             # Apply Hadamards\n",
    "#             for hadamard_wire in range(len(vals)):\n",
    "#                 qml.Hadamard(wires = hadamard_wire)\n",
    "\n",
    "#             # Apply value dependent Z-axis rotations\n",
    "#             for rotation_val in range(len(vals)):\n",
    "#                 qml.RZ(vals[rotation_val], wires = rotation_val)\n",
    "\n",
    "#             # Random CNOT\n",
    "#             qml.CNOT(wires = [1,0])\n",
    "\n",
    "#             # Parametized rotation <- this is what is being trained\n",
    "#             qml.RY(theta, wires=0)\n",
    "\n",
    "#             # Get expected values & return them\n",
    "#             expected_values = [qml.expval(qml.PauliX(wire)) for wire in range(len(vals))]\n",
    "#             return expected_values\n",
    "\n",
    "\n",
    "#         @qml.qnode(self.devY)\n",
    "#         def rotation_circuitY(vals, theta):\n",
    "\n",
    "#             # Apply Hadamards\n",
    "#             for hadamard_wire in range(len(vals)):\n",
    "#                 qml.Hadamard(wires = hadamard_wire)\n",
    "\n",
    "#             # Apply value dependent Z-axis rotations\n",
    "#             for rotation_val in range(len(vals)):\n",
    "#                 qml.RZ(vals[rotation_val], wires = rotation_val)\n",
    "\n",
    "#             # Random CNOT\n",
    "#             qml.CNOT(wires = [1,0])\n",
    "\n",
    "#             # Parametized rotation <- this is what is being trained\n",
    "#             qml.RY(theta, wires=0)\n",
    "\n",
    "#             # Get expected values & return them\n",
    "#             expected_values = [qml.expval(qml.PauliX(wire)) for wire in range(len(vals))]\n",
    "#             return expected_values\n",
    "\n",
    "\n",
    "#         @qml.qnode(self.devZ)\n",
    "#         def rotation_circuitZ(vals, theta):\n",
    "\n",
    "#             # Apply Hadamards\n",
    "#             for hadamard_wire in range(len(vals)):\n",
    "#                 qml.Hadamard(wires = hadamard_wire)\n",
    "\n",
    "#             # Apply value dependent Z-axis rotations\n",
    "#             for rotation_val in range(len(vals)):\n",
    "#                 qml.RZ(vals[rotation_val], wires = rotation_val)\n",
    "\n",
    "#             # Random CNOT\n",
    "#             qml.CNOT(wires = [1,0])\n",
    "\n",
    "#             # Parametized rotation <- this is what is being trained\n",
    "#             qml.RY(theta, wires=0)\n",
    "\n",
    "#             # Get expected values & return them\n",
    "#             expected_values = [qml.expval(qml.PauliX(wire)) for wire in range(len(vals))]\n",
    "#             return expected_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "devX = qml.device('default.qubit', wires = n_vals)\n",
    "devY = qml.device('default.qubit', wires = n_vals)\n",
    "devZ = qml.device('default.qubit', wires = n_vals)\n",
    "\n",
    "@qml.qnode(devX)\n",
    "def rotation_circuitX(vals, thetas):\n",
    "\n",
    "    # Apply Hadamards\n",
    "    for hadamard_wire in range(len(vals)):\n",
    "        qml.Hadamard(wires = hadamard_wire)\n",
    "\n",
    "    # Apply value dependent Z-axis rotations\n",
    "    for rotation_val in range(len(vals)):\n",
    "        qml.RZ(vals[rotation_val], wires = rotation_val)\n",
    "\n",
    "    # Random CNOT\n",
    "    qml.CNOT(wires = [1,0])\n",
    "\n",
    "    # Parametized rotation <- this is what is being trained\n",
    "    for theta in range(len(thetas)):\n",
    "        qml.RY(thetas[theta], wires=theta)\n",
    "\n",
    "    # Get expected values & return them\n",
    "    expected_values = [qml.expval(qml.PauliX(wire)) for wire in range(len(vals))]\n",
    "    return expected_values\n",
    "\n",
    "\n",
    "@qml.qnode(devY)\n",
    "def rotation_circuitY(vals, thetas):\n",
    "\n",
    "    # Apply Hadamards\n",
    "    for hadamard_wire in range(len(vals)):\n",
    "        qml.Hadamard(wires = hadamard_wire)\n",
    "\n",
    "    # Apply value dependent Z-axis rotations\n",
    "    for rotation_val in range(len(vals)):\n",
    "        qml.RZ(vals[rotation_val], wires = rotation_val)\n",
    "\n",
    "    # Random CNOT\n",
    "    qml.CNOT(wires = [1,0])\n",
    "\n",
    "    # Parametized rotation <- this is what is being trained\n",
    "    for theta in range(len(thetas)):\n",
    "        qml.RY(thetas[theta], wires=theta)\n",
    "\n",
    "    # Get expected values & return them\n",
    "    expected_values = [qml.expval(qml.PauliY(wire)) for wire in range(len(vals))]\n",
    "    return expected_values\n",
    "\n",
    "\n",
    "@qml.qnode(devZ)\n",
    "def rotation_circuitZ(vals, thetas):\n",
    "\n",
    "    # Apply Hadamards\n",
    "    for hadamard_wire in range(len(vals)):\n",
    "        qml.Hadamard(wires = hadamard_wire)\n",
    "\n",
    "    # Apply value dependent Z-axis rotations\n",
    "    for rotation_val in range(len(vals)):\n",
    "        qml.RZ(vals[rotation_val], wires = rotation_val)\n",
    "\n",
    "    # Random CNOT\n",
    "    qml.CNOT(wires = [1,0])\n",
    "\n",
    "    # Parametized rotation <- this is what is being trained\n",
    "    for theta in range(len(thetas)):\n",
    "        qml.RY(thetas[theta], wires=theta)\n",
    "\n",
    "    # Get expected values & return them\n",
    "    expected_values = [qml.expval(qml.PauliZ(wire)) for wire in range(len(vals))]\n",
    "    return expected_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 10 into shape (2,)",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-304-e9c6a8eece80>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrotation_circuitX\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda/envs/qnn/lib/python3.8/site-packages/pennylane/tape/qnode.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m         \u001b[0;31m# execute the tape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 533\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m         \u001b[0;31m# FIX: If the qnode swapped the device, increase the num_execution value on the original device.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/qnn/lib/python3.8/site-packages/pennylane/tape/tapes/tape.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, device, params)\u001b[0m\n\u001b[1;32m   1068\u001b[0m             \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1069\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1070\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_execute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1071\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1072\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexecute_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/qnn/lib/python3.8/site-packages/pennylane/tape/tapes/tape.py\u001b[0m in \u001b[0;36mexecute_device\u001b[0;34m(self, params, device)\u001b[0m\n\u001b[1;32m   1099\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mQubitDevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1101\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1102\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1103\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moperations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/qnn/lib/python3.8/site-packages/pennylane/_qubit_device.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, circuit, **kwargs)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;31m# apply all circuit operations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcircuit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moperations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrotations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcircuit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiagonalizing_gates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m         \u001b[0;31m# generate computational basis samples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/qnn/lib/python3.8/site-packages/pennylane/devices/default_qubit.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, operations, rotations, **kwargs)\u001b[0m\n\u001b[1;32m    186\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_basis_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwires\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_operation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;31m# store the pre-rotated state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/qnn/lib/python3.8/site-packages/pennylane/devices/default_qubit.py\u001b[0m in \u001b[0;36m_apply_operation\u001b[0;34m(self, state, operation)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDiagonalOperation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_diagonal_unitary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwires\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwires\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m             \u001b[0;31m# Einsum is faster for small gates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/qnn/lib/python3.8/site-packages/pennylane/devices/default_qubit.py\u001b[0m in \u001b[0;36m_apply_diagonal_unitary\u001b[0;34m(self, state, phases, wires)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m         \u001b[0;31m# reshape vectors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 629\u001b[0;31m         \u001b[0mphases\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphases\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_wires\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mC_DTYPE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    630\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m         \u001b[0mstate_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mABC\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_wires\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/qnn/lib/python3.8/site-packages/pennylane/numpy/wrapper.py\u001b[0m in \u001b[0;36m_wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;31m# evaluate the original object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_np\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/qnn/lib/python3.8/site-packages/autograd/tracer.py\u001b[0m in \u001b[0;36mf_wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mnew_box\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m     \u001b[0mf_wrapped\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfun\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf_raw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0mf_wrapped\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_autograd_primitive\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mreshape\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/qnn/lib/python3.8/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mreshape\u001b[0;34m(a, newshape, order)\u001b[0m\n\u001b[1;32m    297\u001b[0m            [5, 6]])\n\u001b[1;32m    298\u001b[0m     \"\"\"\n\u001b[0;32m--> 299\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'reshape'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/qnn/lib/python3.8/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbound\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;31m# A TypeError occurs if the object does have such a method in its\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 10 into shape (2,)"
     ]
    }
   ],
   "source": [
    "rotation_circuitX(x, theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "'QuantumLayer' object has no attribute 'rotation_circuit'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-305-36772b6b4429>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mQuantumLayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrotation_circuit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m.4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m.4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'QuantumLayer' object has no attribute 'rotation_circuit'"
     ]
    }
   ],
   "source": [
    "QuantumLayer(4).rotation_circuit([.1, .2, .3, .4], .4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Define our model\n",
    "class QuantumCicuitNet(torch.nn.Module):\n",
    "    def __init__(self, n_vals, n_dim):\n",
    "        super().__init__()\n",
    "        # self.thetas = torch.nn.Parameter(torch.tensor(np.random.rand(num_rotations)*.0001, dtype = torch.float32, requires_grad=True))         \n",
    "        # self.QCLX = devX(n_vals)\n",
    "        # self.QCLY = devY(n_vals)\n",
    "        # self.QCLZ = devZ(n_vals)\n",
    "        self.relu = torch.nn.ReLU(inplace=True)\n",
    "        # self.linear = torch.nn.Linear(n_vals * n_dim, n_dim)\n",
    "        self.conv2d = torch.nn.Conv2d(1, 1, kernel_size=(3,5), stride=(2,2), padding=(1,1), bias=False)\n",
    "        self.linear = torch.nn.Linear(4, 1)  \n",
    "\n",
    "\n",
    "    def param_shift(self, vals, thetas, axis):\n",
    "        # using the convention u=1/2\n",
    "        # print(\"Axis: \", axis)\n",
    "        if axis == 'X':\n",
    "            r_plus = rotation_circuitX(vals, np.array(theta) + np.array(np.pi / 2))\n",
    "            r_minus = rotation_circuitX(vals, np.array(theta) - np.array(np.pi / 2))\n",
    "            return 10 * (r_plus - r_minus)\n",
    "        elif axis == 'Y':\n",
    "            r_plus = rotation_circuitY(vals, np.array(theta) + np.array(np.pi / 2))\n",
    "            r_minus = rotation_circuitY(vals, np.array(theta) - np.array(np.pi / 2))\n",
    "            return 10 * (r_plus - r_minus)\n",
    "        elif axis == 'Z':\n",
    "            r_plus = rotation_circuitZ(vals, np.array(theta) + np.array(np.pi / 2))\n",
    "            r_minus = rotation_circuitZ(vals, np.array(theta) - np.array(np.pi / 2))\n",
    "            return .5 * (r_plus - r_minus)\n",
    "            \n",
    "        # print(\"R Minus: \", r_minus)\n",
    "        # print(\"Minus: \", (r_plus - r_minus))\n",
    "        \n",
    "\n",
    "    def calc_circ_grad(self, x, theta, axis):\n",
    "        param_shift_vals = self.param_shift(x, theta, axis)\n",
    "        # print(\"Gradient: \", param_shift_vals)\n",
    "        return param_shift_vals\n",
    "\n",
    "        \n",
    "    def forward(self, x, thetas):\n",
    "        outX = torch.tensor(rotation_circuitX(x, thetas), dtype = torch.float32) * 100# OUT:  torch.Size([100, 1, 10, 10])\n",
    "        outY = torch.tensor(rotation_circuitY(x, thetas), dtype = torch.float32) * 100# OUT:  torch.Size([100, 1, 10, 10])\n",
    "        outZ = torch.tensor(rotation_circuitZ(x, thetas), dtype = torch.float32) * 100# OUT:  torch.Size([100, 1, 10, 10])\n",
    "        out = torch.reshape(torch.cat((outX, outY,outZ), 0), (1, 1, 3, 5))\n",
    "        # print(out)\n",
    "        # print(\"X: \", out)\n",
    "        # print(\"Y: \", outY)\n",
    "        # print(\"Z: \", outZ)\n",
    "        # print()\n",
    "        # exp_vals = deepcopy(out)\n",
    "        gradX = torch.tensor(self.calc_circ_grad(x, thetas, 'X'))\n",
    "        gradY = torch.tensor(self.calc_circ_grad(x, thetas, 'Y'))\n",
    "        gradZ = torch.tensor(self.calc_circ_grad(x, thetas, 'Z'))\n",
    "        grads = torch.reshape(torch.cat((gradX, gradY,gradZ), 0), (3,5))\n",
    "        # print(grads)\n",
    "        grads = torch.mean(input = grads, dim = 0)\n",
    "        # print(\"Grads: \", torch.mean(input = grads, dim = 0))\n",
    "        # print(\"GradY: \", gradY)\n",
    "        # print(\"GradZ: \", gradZ)\n",
    "        # torch.mean()\n",
    "        out = self.conv2d(out)\n",
    "        out = self.relu(out)\n",
    "        out = out.flatten()\n",
    "        out = self.linear(out)\n",
    "        return out, grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[0.2898364  0.15086376 0.01904088 0.17205208 0.13949271]]\ntensor(961.)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "devSet = pd.read_csv(\"./us_migration.csv\")\n",
    "devSet = devSet.loc[:, ~devSet.columns.str.contains('^Unnamed')]\n",
    "devSet = devSet.apply(lambda x: pd.to_numeric(x, errors='coerce'))\n",
    "devSet = devSet.dropna(axis=1)\n",
    "\n",
    "y = torch.Tensor(devSet['US_MIG_05_10'].values)\n",
    "X = devSet.loc[:, devSet.columns != \"US_MIG_05_10\"].values\n",
    "\n",
    "mMScale = preprocessing.MinMaxScaler()\n",
    "X = mMScale.fit_transform(X)\n",
    "\n",
    "x = np.reshape(X[0][0:5], (1, 5))\n",
    "y = torch.tensor(y.detach().numpy()[0])\n",
    "\n",
    "print(x)\n",
    "print(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ard>)\n",
      "    Y pred:  tensor([955.7786], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "EPOCH:  338\n",
      "    Loss:  tensor(24.7267, grad_fn=<MseLossBackward>)\n",
      "    Y pred:  tensor([956.0274], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "EPOCH:  339\n",
      "    Loss:  tensor(22.4276, grad_fn=<MseLossBackward>)\n",
      "    Y pred:  tensor([956.2642], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "EPOCH:  340\n",
      "    Loss:  tensor(20.3418, grad_fn=<MseLossBackward>)\n",
      "    Y pred:  tensor([956.4898], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "EPOCH:  341\n",
      "    Loss:  tensor(18.4490, grad_fn=<MseLossBackward>)\n",
      "    Y pred:  tensor([956.7048], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "EPOCH:  342\n",
      "    Loss:  tensor(16.7333, grad_fn=<MseLossBackward>)\n",
      "    Y pred:  tensor([956.9094], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "EPOCH:  343\n",
      "    Loss:  tensor(15.1759, grad_fn=<MseLossBackward>)\n",
      "    Y pred:  tensor([957.1044], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "EPOCH:  344\n",
      "    Loss:  tensor(13.7634, grad_fn=<MseLossBackward>)\n",
      "    Y pred:  tensor([957.2901], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "EPOCH:  345\n",
      "    Loss:  tensor(12.4831, grad_fn=<MseLossBackward>)\n",
      "    Y pred:  tensor([957.4669], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "EPOCH:  346\n",
      "    Loss:  tensor(11.3211, grad_fn=<MseLossBackward>)\n",
      "    Y pred:  tensor([957.6353], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "EPOCH:  347\n",
      "    Loss:  tensor(10.2674, grad_fn=<MseLossBackward>)\n",
      "    Y pred:  tensor([957.7957], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "EPOCH:  348\n",
      "    Loss:  tensor(9.3121, grad_fn=<MseLossBackward>)\n",
      "    Y pred:  tensor([957.9484], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "EPOCH:  349\n",
      "    Loss:  tensor(8.4452, grad_fn=<MseLossBackward>)\n",
      "    Y pred:  tensor([958.0939], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "EPOCH:  350\n",
      "    Loss:  tensor(7.6595, grad_fn=<MseLossBackward>)\n",
      "    Y pred:  tensor([958.2324], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "EPOCH:  351\n",
      "    Loss:  tensor(6.9468, grad_fn=<MseLossBackward>)\n",
      "    Y pred:  tensor([958.3643], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "EPOCH:  352\n",
      "    Loss:  tensor(6.3005, grad_fn=<MseLossBackward>)\n",
      "    Y pred:  tensor([958.4899], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "EPOCH:  353\n",
      "    Loss:  tensor(5.7142, grad_fn=<MseLossBackward>)\n",
      "    Y pred:  tensor([958.6096], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "EPOCH:  354\n",
      "    Loss:  tensor(5.1830, grad_fn=<MseLossBackward>)\n",
      "    Y pred:  tensor([958.7234], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "EPOCH:  355\n",
      "    Loss:  tensor(4.7009, grad_fn=<MseLossBackward>)\n",
      "    Y pred:  tensor([958.8318], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "EPOCH:  356\n",
      "    Loss:  tensor(4.2637, grad_fn=<MseLossBackward>)\n",
      "    Y pred:  tensor([958.9351], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "EPOCH:  357\n",
      "    Loss:  tensor(3.8671, grad_fn=<MseLossBackward>)\n",
      "    Y pred:  tensor([959.0335], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "EPOCH:  358\n",
      "    Loss:  tensor(3.5074, grad_fn=<MseLossBackward>)\n",
      "    Y pred:  tensor([959.1272], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "EPOCH:  359\n",
      "    Loss:  tensor(3.1820, grad_fn=<MseLossBackward>)\n",
      "    Y pred:  tensor([959.2162], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "EPOCH:  360\n",
      "    Loss:  tensor(2.8861, grad_fn=<MseLossBackward>)\n",
      "    Y pred:  tensor([959.3011], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "EPOCH:  361\n",
      "    Loss:  tensor(2.6181, grad_fn=<MseLossBackward>)\n",
      "    Y pred:  tensor([959.3820], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "EPOCH:  362\n",
      "    Loss:  tensor(2.3747, grad_fn=<MseLossBackward>)\n",
      "    Y pred:  tensor([959.4590], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "EPOCH:  363\n",
      "    Loss:  tensor(2.1542, grad_fn=<MseLossBackward>)\n",
      "    Y pred:  tensor([959.5323], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "EPOCH:  364\n",
      "    Loss:  tensor(1.9546, grad_fn=<MseLossBackward>)\n",
      "    Y pred:  tensor([959.6019], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "EPOCH:  365\n",
      "    Loss:  tensor(1.7732, grad_fn=<MseLossBackward>)\n",
      "    Y pred:  tensor([959.6684], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "EPOCH:  366\n",
      "    Loss:  tensor(1.6088, grad_fn=<MseLossBackward>)\n",
      "    Y pred:  tensor([959.7316], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "EPOCH:  367\n",
      "    Loss:  tensor(1.4596, grad_fn=<MseLossBackward>)\n",
      "    Y pred:  tensor([959.7919], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "EPOCH:  368\n",
      "    Loss:  tensor(1.3244, grad_fn=<MseLossBackward>)\n",
      "    Y pred:  tensor([959.8492], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "EPOCH:  369\n",
      "    Loss:  tensor(1.2016, grad_fn=<MseLossBackward>)\n",
      "    Y pred:  tensor([959.9038], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "EPOCH:  370\n",
      "    Loss:  tensor(1.0903, grad_fn=<MseLossBackward>)\n",
      "    Y pred:  tensor([959.9558], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "EPOCH:  371\n",
      "    Loss:  tensor(0.9894, grad_fn=<MseLossBackward>)\n",
      "    Y pred:  tensor([960.0053], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "EPOCH:  372\n",
      "    Loss:  tensor(0.8979, grad_fn=<MseLossBackward>)\n",
      "    Y pred:  tensor([960.0524], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "EPOCH:  373\n",
      "    Loss:  tensor(0.8150, grad_fn=<MseLossBackward>)\n",
      "    Y pred:  tensor([960.0972], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "EPOCH:  374\n",
      "    Loss:  tensor(0.7397, grad_fn=<MseLossBackward>)\n",
      "    Y pred:  tensor([960.1400], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "EPOCH:  375\n",
      "    Loss:  tensor(0.6714, grad_fn=<MseLossBackward>)\n",
      "    Y pred:  tensor([960.1806], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "EPOCH:  376\n",
      "    Loss:  tensor(0.6093, grad_fn=<MseLossBackward>)\n",
      "    Y pred:  tensor([960.2194], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "EPOCH:  377\n",
      "    Loss:  tensor(0.5532, grad_fn=<MseLossBackward>)\n",
      "    Y pred:  tensor([960.2562], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "EPOCH:  378\n",
      "    Loss:  tensor(0.5022, grad_fn=<MseLossBackward>)\n",
      "    Y pred:  tensor([960.2913], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "EPOCH:  379\n",
      "    Loss:  tensor(0.4561, grad_fn=<MseLossBackward>)\n",
      "    Y pred:  tensor([960.3246], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "EPOCH:  380\n",
      "    Loss:  tensor(0.4140, grad_fn=<MseLossBackward>)\n",
      "    Y pred:  tensor([960.3566], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "EPOCH:  381\n",
      "    Loss:  tensor(0.3760, grad_fn=<MseLossBackward>)\n",
      "    Y pred:  tensor([960.3868], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "EPOCH:  382\n",
      "    Loss:  tensor(0.3415, grad_fn=<MseLossBackward>)\n",
      "    Y pred:  tensor([960.4156], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "EPOCH:  383\n",
      "    Loss:  tensor(0.3101, grad_fn=<MseLossBackward>)\n",
      "    Y pred:  tensor([960.4431], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "EPOCH:  384\n",
      "    Loss:  tensor(0.2818, grad_fn=<MseLossBackward>)\n",
      "    Y pred:  tensor([960.4692], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "EPOCH:  385\n",
      "    Loss:  tensor(0.2559, grad_fn=<MseLossBackward>)\n",
      "    Y pred:  tensor([960.4941], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "EPOCH:  386\n",
      "    Loss:  tensor(0.2325, grad_fn=<MseLossBackward>)\n",
      "    Y pred:  tensor([960.5178], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "EPOCH:  387\n",
      "    Loss:  tensor(0.2112, grad_fn=<MseLossBackward>)\n",
      "    Y pred:  tensor([960.5404], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "EPOCH:  388\n",
      "    Loss:  tensor(0.1919, grad_fn=<MseLossBackward>)\n",
      "    Y pred:  tensor([960.5620], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "EPOCH:  389\n",
      "    Loss:  tensor(0.1744, grad_fn=<MseLossBackward>)\n",
      "    Y pred:  tensor([960.5824], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "EPOCH:  390\n",
      "    Loss:  tensor(0.1586, grad_fn=<MseLossBackward>)\n",
      "    Y pred:  tensor([960.6018], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "EPOCH:  391\n",
      "    Loss:  tensor(0.1441, grad_fn=<MseLossBackward>)\n",
      "    Y pred:  tensor([960.6204], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "EPOCH:  392\n",
      "    Loss:  tensor(0.1310, grad_fn=<MseLossBackward>)\n",
      "    Y pred:  tensor([960.6380], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "EPOCH:  393\n",
      "    Loss:  tensor(0.1192, grad_fn=<MseLossBackward>)\n",
      "    Y pred:  tensor([960.6547], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "EPOCH:  394\n",
      "    Loss:  tensor(0.1083, grad_fn=<MseLossBackward>)\n",
      "    Y pred:  tensor([960.6709], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "EPOCH:  395\n",
      "    Loss:  tensor(0.0986, grad_fn=<MseLossBackward>)\n",
      "    Y pred:  tensor([960.6860], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "EPOCH:  396\n",
      "    Loss:  tensor(0.0897, grad_fn=<MseLossBackward>)\n",
      "    Y pred:  tensor([960.7004], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "EPOCH:  397\n",
      "    Loss:  tensor(0.0817, grad_fn=<MseLossBackward>)\n",
      "    Y pred:  tensor([960.7142], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "EPOCH:  398\n",
      "    Loss:  tensor(0.0743, grad_fn=<MseLossBackward>)\n",
      "    Y pred:  tensor([960.7275], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "EPOCH:  399\n",
      "    Loss:  tensor(0.0676, grad_fn=<MseLossBackward>)\n",
      "    Y pred:  tensor([960.7400], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "EPOCH:  400\n",
      "    Loss:  tensor(0.0616, grad_fn=<MseLossBackward>)\n",
      "    Y pred:  tensor([960.7518], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "EPOCH:  401\n",
      "    Loss:  tensor(0.0561, grad_fn=<MseLossBackward>)\n",
      "    Y pred:  tensor([960.7632], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "EPOCH:  402\n",
      "    Loss:  tensor(0.0511, grad_fn=<MseLossBackward>)\n",
      "    Y pred:  tensor([960.7740], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "EPOCH:  403\n",
      "    Loss:  tensor(0.0466, grad_fn=<MseLossBackward>)\n",
      "    Y pred:  tensor([960.7842], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "EPOCH:  404\n",
      "    Loss:  tensor(0.0425, grad_fn=<MseLossBackward>)\n",
      "    Y pred:  tensor([960.7939], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "EPOCH:  405\n",
      "    Loss:  tensor(0.0386, grad_fn=<MseLossBackward>)\n",
      "    Y pred:  tensor([960.8035], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "EPOCH:  406\n",
      "    Loss:  tensor(0.0352, grad_fn=<MseLossBackward>)\n",
      "    Y pred:  tensor([960.8123], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "EPOCH:  407\n",
      "    Loss:  tensor(0.0322, grad_fn=<MseLossBackward>)\n",
      "    Y pred:  tensor([960.8206], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "EPOCH:  408\n",
      "    Loss:  tensor(0.0294, grad_fn=<MseLossBackward>)\n",
      "    Y pred:  tensor([960.8287], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "EPOCH:  409\n",
      "    Loss:  tensor(0.0268, grad_fn=<MseLossBackward>)\n",
      "    Y pred:  tensor([960.8362], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "EPOCH:  410\n",
      "    Loss:  tensor(0.0245, grad_fn=<MseLossBackward>)\n",
      "    Y pred:  tensor([960.8436], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "EPOCH:  411\n",
      "    Loss:  tensor(0.0224, grad_fn=<MseLossBackward>)\n",
      "    Y pred:  tensor([960.8505], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "EPOCH:  412\n",
      "    Loss:  tensor(0.0204, grad_fn=<MseLossBackward>)\n",
      "    Y pred:  tensor([960.8571], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "EPOCH:  413\n",
      "    Loss:  tensor(0.0187, grad_fn=<MseLossBackward>)\n",
      "    Y pred:  tensor([960.8633], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "EPOCH:  414\n",
      "    Loss:  tensor(0.0171, grad_fn=<MseLossBackward>)\n",
      "    Y pred:  tensor([960.8694], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "EPOCH:  415\n",
      "    Loss:  tensor(0.0156, grad_fn=<MseLossBackward>)\n",
      "    Y pred:  tensor([960.8750], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "EPOCH:  416\n",
      "    Loss:  tensor(0.0143, grad_fn=<MseLossBackward>)\n",
      "    Y pred:  tensor([960.8804], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "EPOCH:  417\n",
      "    Loss:  tensor(0.0131, grad_fn=<MseLossBackward>)\n",
      "    Y pred:  tensor([960.8856], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "EPOCH:  418\n",
      "    Loss:  tensor(0.0120, grad_fn=<MseLossBackward>)\n",
      "    Y pred:  tensor([960.8905], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "EPOCH:  419\n",
      "    Loss:  tensor(0.0110, grad_fn=<MseLossBackward>)\n",
      "    Y pred:  tensor([960.8951], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "EPOCH:  420\n",
      "    Loss:  tensor(0.0101, grad_fn=<MseLossBackward>)\n",
      "    Y pred:  tensor([960.8997], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "EPOCH:  421\n",
      "    Loss:  tensor(0.0092, grad_fn=<MseLossBackward>)\n",
      "    Y pred:  tensor([960.9039], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "EPOCH:  422\n",
      "    Loss:  tensor(0.0085, grad_fn=<MseLossBackward>)\n",
      "    Y pred:  tensor([960.9079], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "EPOCH:  423\n",
      "    Loss:  tensor(0.0078, grad_fn=<MseLossBackward>)\n",
      "    Y pred:  tensor([960.9117], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "EPOCH:  424\n",
      "    Loss:  tensor(0.0072, grad_fn=<MseLossBackward>)\n",
      "    Y pred:  tensor([960.9154], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "EPOCH:  425\n",
      "    Loss:  tensor(0.0066, grad_fn=<MseLossBackward>)\n",
      "    Y pred:  tensor([960.9189], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "EPOCH:  426\n",
      "    Loss:  tensor(0.0060, grad_fn=<MseLossBackward>)\n",
      "    Y pred:  tensor([960.9222], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "EPOCH:  427\n",
      "    Loss:  tensor(0.0056, grad_fn=<MseLossBackward>)\n",
      "    Y pred:  tensor([960.9254], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "EPOCH:  428\n",
      "    Loss:  tensor(0.0051, grad_fn=<MseLossBackward>)\n",
      "    Y pred:  tensor([960.9283], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "EPOCH:  429\n",
      "    Loss:  tensor(0.0047, grad_fn=<MseLossBackward>)\n",
      "    Y pred:  tensor([960.9312], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "EPOCH:  430\n",
      "    Loss:  tensor(0.0043, grad_fn=<MseLossBackward>)\n",
      "    Y pred:  tensor([960.9341], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "EPOCH:  431\n",
      "    Loss:  tensor(0.0040, grad_fn=<MseLossBackward>)\n",
      "    Y pred:  tensor([960.9366], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "EPOCH:  432\n",
      "    Loss:  tensor(0.0037, grad_fn=<MseLossBackward>)\n",
      "    Y pred:  tensor([960.9391], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "EPOCH:  433\n",
      "    Loss:  tensor(0.0034, grad_fn=<MseLossBackward>)\n",
      "    Y pred:  tensor([960.9414], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "EPOCH:  434\n",
      "    Loss:  tensor(0.0032, grad_fn=<MseLossBackward>)\n",
      "    Y pred:  tensor([960.9437], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "EPOCH:  435\n",
      "    Loss:  tensor(0.0029, grad_fn=<MseLossBackward>)\n",
      "    Y pred:  tensor([960.9459], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "EPOCH:  436\n",
      "    Loss:  tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "    Y pred:  tensor([960.9478], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "EPOCH:  437\n",
      "    Loss:  tensor(0.0025, grad_fn=<MseLossBackward>)\n",
      "    Y pred:  tensor([960.9497], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "EPOCH:  438\n",
      "    Loss:  tensor(0.0023, grad_fn=<MseLossBackward>)\n",
      "    Y pred:  tensor([960.9516], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "EPOCH:  439\n",
      "    Loss:  tensor(0.0022, grad_fn=<MseLossBackward>)\n",
      "    Y pred:  tensor([960.9534], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "EPOCH:  440\n",
      "    Loss:  tensor(0.0020, grad_fn=<MseLossBackward>)\n",
      "    Y pred:  tensor([960.9550], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "EPOCH:  441\n",
      "    Loss:  tensor(0.0019, grad_fn=<MseLossBackward>)\n",
      "    Y pred:  tensor([960.9565], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "EPOCH:  442\n",
      "    Loss:  tensor(0.0018, grad_fn=<MseLossBackward>)\n",
      "    Y pred:  tensor([960.9581], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "EPOCH:  443\n",
      "    Loss:  tensor(0.0016, grad_fn=<MseLossBackward>)\n",
      "    Y pred:  tensor([960.9595], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "EPOCH:  444\n",
      "    Loss:  tensor(0.0015, grad_fn=<MseLossBackward>)\n",
      "    Y pred:  tensor([960.9609], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "EPOCH:  445\n",
      "    Loss:  tensor(0.0014, grad_fn=<MseLossBackward>)\n",
      "    Y pred:  tensor([960.9622], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "EPOCH:  446\n",
      "    Loss:  tensor(0.0013, grad_fn=<MseLossBackward>)\n",
      "    Y pred:  tensor([960.9635], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "EPOCH:  447\n",
      "    Loss:  tensor(0.0013, grad_fn=<MseLossBackward>)\n",
      "    Y pred:  tensor([960.9646], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "EPOCH:  448\n",
      "    Loss:  tensor(0.0012, grad_fn=<MseLossBackward>)\n",
      "    Y pred:  tensor([960.9657], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "EPOCH:  449\n",
      "    Loss:  tensor(0.0011, grad_fn=<MseLossBackward>)\n",
      "    Y pred:  tensor([960.9668], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "EPOCH:  450\n",
      "    Loss:  tensor(0.0010, grad_fn=<MseLossBackward>)\n",
      "    Y pred:  tensor([960.9678], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "EPOCH:  451\n",
      "    Loss:  tensor(0.0010, grad_fn=<MseLossBackward>)\n",
      "    Y pred:  tensor([960.9688], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "EPOCH:  452\n",
      "    Loss:  tensor(0.0009, grad_fn=<MseLossBackward>)\n",
      "    Y pred:  tensor([960.9696], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "EPOCH:  453\n",
      "    Loss:  tensor(0.0009, grad_fn=<MseLossBackward>)\n",
      "    Y pred:  tensor([960.9706], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "EPOCH:  454\n",
      "    Loss:  tensor(0.0008, grad_fn=<MseLossBackward>)\n",
      "    Y pred:  tensor([960.9714], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "EPOCH:  455\n",
      "    Loss:  tensor(0.0008, grad_fn=<MseLossBackward>)\n",
      "    Y pred:  tensor([960.9723], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "EPOCH:  456\n",
      "    Loss:  tensor(0.0007, grad_fn=<MseLossBackward>)\n",
      "    Y pred:  tensor([960.9729], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "EPOCH:  457\n",
      "    Loss:  tensor(0.0007, grad_fn=<MseLossBackward>)\n",
      "    Y pred:  tensor([960.9736], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "EPOCH:  458\n",
      "    Loss:  tensor(0.0007, grad_fn=<MseLossBackward>)\n",
      "    Y pred:  tensor([960.9744], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "EPOCH:  459\n",
      "    Loss:  tensor(0.0006, grad_fn=<MseLossBackward>)\n",
      "    Y pred:  tensor([960.9750], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "EPOCH:  460\n",
      "    Loss:  tensor(0.0006, grad_fn=<MseLossBackward>)\n",
      "    Y pred:  tensor([960.9756], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "EPOCH:  461\n",
      "    Loss:  tensor(0.0006, grad_fn=<MseLossBackward>)\n",
      "    Y pred:  tensor([960.9763], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "EPOCH:  462\n",
      "    Loss:  tensor(0.0005, grad_fn=<MseLossBackward>)\n",
      "    Y pred:  tensor([960.9767], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "EPOCH:  463\n",
      "    Loss:  tensor(0.0005, grad_fn=<MseLossBackward>)\n",
      "    Y pred:  tensor([960.9773], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "EPOCH:  464\n",
      "    Loss:  tensor(0.0005, grad_fn=<MseLossBackward>)\n",
      "    Y pred:  tensor([960.9778], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "EPOCH:  465\n",
      "    Loss:  tensor(0.0005, grad_fn=<MseLossBackward>)\n",
      "    Y pred:  tensor([960.9783], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "EPOCH:  466\n",
      "    Loss:  tensor(0.0005, grad_fn=<MseLossBackward>)\n",
      "    Y pred:  tensor([960.9788], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "EPOCH:  467\n",
      "    Loss:  tensor(0.0004, grad_fn=<MseLossBackward>)\n",
      "    Y pred:  tensor([960.9791], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "EPOCH:  468\n",
      "    Loss:  tensor(0.0004, grad_fn=<MseLossBackward>)\n",
      "    Y pred:  tensor([960.9796], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "EPOCH:  469\n",
      "    Loss:  tensor(0.0004, grad_fn=<MseLossBackward>)\n",
      "    Y pred:  tensor([960.9800], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "EPOCH:  470\n",
      "    Loss:  tensor(0.0004, grad_fn=<MseLossBackward>)\n",
      "    Y pred:  tensor([960.9805], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "EPOCH:  471\n",
      "    Loss:  tensor(0.0004, grad_fn=<MseLossBackward>)\n",
      "    Y pred:  tensor([960.9808], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "EPOCH:  472\n",
      "    Loss:  tensor(0.0004, grad_fn=<MseLossBackward>)\n",
      "    Y pred:  tensor([960.9812], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "EPOCH:  473\n",
      "    Loss:  tensor(0.0003, grad_fn=<MseLossBackward>)\n",
      "    Y pred:  tensor([960.9816], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "EPOCH:  474\n",
      "    Loss:  tensor(0.0003, grad_fn=<MseLossBackward>)\n",
      "    Y pred:  tensor([960.9818], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "EPOCH:  475\n",
      "    Loss:  tensor(0.0003, grad_fn=<MseLossBackward>)\n",
      "    Y pred:  tensor([960.9821], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "EPOCH:  476\n",
      "    Loss:  tensor(0.0003, grad_fn=<MseLossBackward>)\n",
      "    Y pred:  tensor([960.9823], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "EPOCH:  477\n",
      "    Loss:  tensor(0.0003, grad_fn=<MseLossBackward>)\n",
      "    Y pred:  tensor([960.9825], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "EPOCH:  478\n",
      "    Loss:  tensor(0.0003, grad_fn=<MseLossBackward>)\n",
      "    Y pred:  tensor([960.9828], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "EPOCH:  479\n",
      "    Loss:  tensor(0.0003, grad_fn=<MseLossBackward>)\n",
      "    Y pred:  tensor([960.9829], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "EPOCH:  480\n",
      "    Loss:  tensor(0.0003, grad_fn=<MseLossBackward>)\n",
      "    Y pred:  tensor([960.9833], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "EPOCH:  481\n",
      "    Loss:  tensor(0.0003, grad_fn=<MseLossBackward>)\n",
      "    Y pred:  tensor([960.9835], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "EPOCH:  482\n",
      "    Loss:  tensor(0.0003, grad_fn=<MseLossBackward>)\n",
      "    Y pred:  tensor([960.9838], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "EPOCH:  483\n",
      "    Loss:  tensor(0.0003, grad_fn=<MseLossBackward>)\n",
      "    Y pred:  tensor([960.9839], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "EPOCH:  484\n",
      "    Loss:  tensor(0.0003, grad_fn=<MseLossBackward>)\n",
      "    Y pred:  tensor([960.9841], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "EPOCH:  485\n",
      "    Loss:  tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "    Y pred:  tensor([960.9844], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "EPOCH:  486\n",
      "    Loss:  tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "    Y pred:  tensor([960.9846], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "EPOCH:  487\n",
      "    Loss:  tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "    Y pred:  tensor([960.9849], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "EPOCH:  488\n",
      "    Loss:  tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "    Y pred:  tensor([960.9849], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "EPOCH:  489\n",
      "    Loss:  tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "    Y pred:  tensor([960.9851], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "EPOCH:  490\n",
      "    Loss:  tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "    Y pred:  tensor([960.9852], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "EPOCH:  491\n",
      "    Loss:  tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "    Y pred:  tensor([960.9852], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "EPOCH:  492\n",
      "    Loss:  tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "    Y pred:  tensor([960.9853], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "EPOCH:  493\n",
      "    Loss:  tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "    Y pred:  tensor([960.9855], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "EPOCH:  494\n",
      "    Loss:  tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "    Y pred:  tensor([960.9855], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "EPOCH:  495\n",
      "    Loss:  tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "    Y pred:  tensor([960.9856], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "EPOCH:  496\n",
      "    Loss:  tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "    Y pred:  tensor([960.9857], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "EPOCH:  497\n",
      "    Loss:  tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "    Y pred:  tensor([960.9857], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "EPOCH:  498\n",
      "    Loss:  tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "    Y pred:  tensor([960.9857], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "EPOCH:  499\n",
      "    Loss:  tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "    Y pred:  tensor([960.9858], grad_fn=<AddBackward0>)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr = 1e-7\n",
    "model = QuantumCicuitNet(5, 1)\n",
    "thetas = [.5] * 5\n",
    "\n",
    "criterion = torch.nn.MSELoss(reduction='sum')\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = lr)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i in range(0, 500):\n",
    "\n",
    "    print(\"EPOCH: \", i)\n",
    "\n",
    "    y_pred, grad = model([0.2898364, 0.15086376, 0.01904088, 0.17205208, 0.13949271], thetas)\n",
    "\n",
    "    loss = criterion(y_pred, y)\n",
    "\n",
    "    print(\"    Loss: \", loss)\n",
    "\n",
    "    print(\"    Y pred: \", y_pred)\n",
    "    # print(\"Gradient: \", gradient[0])\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    thetas = [i.item() for i in list(torch.tensor(thetas) + (grad * lr))]\n",
    "\n",
    "    # print(\"New theta: \", [i.item() for i in list(torch.tensor(thetas) - (grad * lr))])\n",
    "\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "conv2d.weight\nlinear.weight\nlinear.bias\n"
     ]
    }
   ],
   "source": [
    "for n, p in model.named_parameters():\n",
    "    print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([2.07079633, 2.07079633, 2.07079633, 2.07079633, 2.07079633])"
      ]
     },
     "metadata": {},
     "execution_count": 320
    }
   ],
   "source": [
    "np.array([.5] * 5) + np.array([np.pi/2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[[[ -0.1390, -23.0678],\n",
       "          [ -7.6440,  -7.7049]]]], grad_fn=<ThnnConv2DBackward>)"
      ]
     },
     "metadata": {},
     "execution_count": 244
    }
   ],
   "source": [
    "conv2d = torch.nn.Conv2d(1, 1, kernel_size=(3,5), stride=(2,2), padding=(1,1), bias=False)\n",
    "hm = conv2d(torch.tensor([[[[ 8.4098e+01,  9.4741e+01,  9.9982e+01,  9.8524e+01,  9.9029e+01],\n",
    "        [ 0.0000e+00,  1.4402e+01,  1.9040e+00,  1.7120e+01,  1.3904e+01],\n",
    "        [-4.5943e+01,  0.0000e+00,  0.0000e+00, -5.5511e-15,  0.0000e+00]]]]))\n",
    "hm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([3.2217], grad_fn=<AddBackward0>)"
      ]
     },
     "metadata": {},
     "execution_count": 246
    }
   ],
   "source": [
    "linear = torch.nn.Linear(4, 1)  \n",
    "\n",
    "linear(hm.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'angles' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-132-b9aca874a87a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mgradient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mqml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrotation_circuit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margnum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# grad_vals = [gradient(theta) for theta in angles]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mexpvals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mrotation_circuit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m.14\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m.80\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtheta\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mangles\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mparam_shift_vals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mparam_shift\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m.14\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m.80\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtheta\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mangles\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'angles' is not defined"
     ]
    }
   ],
   "source": [
    "gradient = qml.grad(rotation_circuit, argnum=0)\n",
    "# grad_vals = [gradient(theta) for theta in angles]\n",
    "expvals = [rotation_circuit([.14, .80], theta) for theta in angles]\n",
    "param_shift_vals = [param_shift([.14, .80], theta) for theta in angles]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}